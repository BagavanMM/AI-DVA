[
  {
    "bug_id": "OT-21517",
    "title": "[rv_dm,dv] Smoke vseq is broken for some seeds",
    "description": "### Description\n\nFor some seeds, the rv_dm smoke vseq fails with the following error:\r\n```\r\nUVM_ERROR @  18026231 ps: (jtag_dmi_monitor.sv:105) uvm_test_top.env.m_jtag_dmi_monitor [uvm_test_top.env.m_jtag_dmi_monitor] Non-ok response seen with no previous DMI request.\r\n```\r\n\r\nThe bug is *old* and dates back to at least early 2023. Stepping further back is a bit hard because of (I suspect) unrelated fixes. For an example which shows the problem that far back, run:\r\n```\r\nutil/dvsim/dvsim.py hw/ip/rv_dm/dv/rv_dm_sim_cfg.hjson --tool=xcelium -i rv_dm_smoke --fixed-seed 355\r\n```\r\n",
    "error_message": "\nFor some seeds, the rv_dm smoke vseq fails with the following error:\r\n```\r\nUVM_ERROR @  18026231 ps: (jtag_dmi_monitor.sv:105) uvm_test_top.env.m_jtag_dmi_monitor [uvm_test_top.env.m_jtag_dmi_monitor] Non-ok response seen with no previous DMI request.\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2024-02-15T14:38:41Z",
    "updated_at": "2025-01-14T11:12:46Z",
    "closed_at": "2024-04-17T13:40:13Z",
    "url": "https://github.com/lowRISC/opentitan/issues/21517",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/21517/comments"
  },
  {
    "bug_id": "OT-20565",
    "title": "[entropy_src/dv] Find out what happened to the group coverage",
    "description": "### Description\r\n\r\nBetween the 16. and the 19. of October something caused the entropy source coverage to plummet to around 30 to 40%.\r\nTo verify this I ran the following command with a 0.1 reseed-multiplier:\r\n``./util/dvsim/dvsim.py hw/ip/entropy_src/dv/entropy_src_sim_cfg.hjson -i all -t vcs --reseed-multiplier 0.1 --cov\r\n``\r\n![image](https://github.com/lowRISC/opentitan/assets/93996688/5d19481a-1c86-4ffb-b29b-a19a23951e16)\r\n\r\nWe need to find out what happened and fix this issue.",
    "error_message": null,
    "module": "entropy_src",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "coverage regression or config issue",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:entropy_src"
    ],
    "state": "closed",
    "created_at": "2023-12-05T12:59:41Z",
    "updated_at": "2025-01-14T11:12:44Z",
    "closed_at": "2023-12-12T06:35:37Z",
    "url": "https://github.com/lowRISC/opentitan/issues/20565",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/20565/comments"
  },
  {
    "bug_id": "OT-20300",
    "title": "[EDN/test] edn_disable_auto_req_mode failing with xcelium",
    "description": "### Description\n\nWhenever tests are run locally with xcelium like the following:\r\n`util/dvsim/dvsim.py ./hw/ip/edn/dv/edn_sim_cfg.hjson -i all -t xcelium --reseed-multiplier 0.2`\r\naround 10 tests fail, all of them are edn_disable_auto_req_mode.\r\nThis needs to be investigated and fixed.",
    "error_message": null,
    "module": "edn",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:edn"
    ],
    "state": "closed",
    "created_at": "2023-11-09T08:00:27Z",
    "updated_at": "2025-01-14T11:12:43Z",
    "closed_at": "2023-11-14T22:31:48Z",
    "url": "https://github.com/lowRISC/opentitan/issues/20300",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/20300/comments"
  },
  {
    "bug_id": "OT-19568",
    "title": "[csrng] SW instance instantiate command hangs after entropy complex initialization",
    "description": "### Description\n\nIn https://github.com/lowRISC/opentitan/pull/19548 we observed a hang when trying to run the `csrng` instantiate command right after initializing the entropy complex in continuous mode. \r\n\r\nThe current workaround is to check for the `MAIN_SM_STATE` register to report `MainSmIdle` state before issuing any commands to the `csrng` interface. Checking the [`SW_CMD_STS`](https://opentitan.org/book/hw/ip/csrng/doc/registers.html#sw_cmd_sts) `CMD_RDY` flag does not seem to help. \r\n\r\nDuring debugging we noticed that the main FSM gets stuck in `MainSmParseCmd` when the instantiate command is sent before the FSM is in `MainSmIdle` state. We'll have to reproduce the test in simulation to be able to debug further. ",
    "error_message": null,
    "module": "csrng",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "Type:Enhancement",
      "Component:RTL",
      "Subsystem:Entropy",
      "IP:csrng"
    ],
    "state": "closed",
    "created_at": "2023-08-31T21:54:56Z",
    "updated_at": "2024-04-23T12:21:42Z",
    "closed_at": "2024-04-22T21:44:28Z",
    "url": "https://github.com/lowRISC/opentitan/issues/19568",
    "comments_count": 6,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/19568/comments"
  },
  {
    "bug_id": "OT-19268",
    "title": "[dv/ecc] Make error injection more reliable",
    "description": "### Description\n\nThe tests that inject an ecc error (like chip_sw_data_integrity_escalation) have occasional failures because flipping bits doesn't always cause ECC errors. This is related to https://github.com/lowRISC/opentitan/issues/10976.\r\n\r\nIn order to make these tests more reliable it would be desirable to change the code so it attempts to inject an error multiple times, and each time it checks ECC in the post-scramble data, stopping when an error is actually detected. This probably means creating functions in chip_sw_base_vseq for at least main and retention sram that perform this operation.\r\n\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "Milestone:V3"
    ],
    "state": "closed",
    "created_at": "2023-07-21T17:47:30Z",
    "updated_at": "2023-08-09T00:22:19Z",
    "closed_at": "2023-08-09T00:22:19Z",
    "url": "https://github.com/lowRISC/opentitan/issues/19268",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/19268/comments"
  },
  {
    "bug_id": "OT-19263",
    "title": "[tlul] sequence item constraints miss to create proper transactions.",
    "description": "### Description\n\nI encountered this issue while debugging one block level tl_errors test.\r\n\r\nFrom section 4.6 of the tile link spec 1.7.1 (current design supports),\r\n\r\n\"The mask is also used for messages without a data payload. When the operation size is smaller\r\nthan the data bus, the mask should be generated identically to an operation which does carry a\r\ndata payload.\"\r\n\r\nFor the \"Get\" transaction with size 1, it should have a contiguous 2bits mask based on address[1:0].\r\nTransactions that do not adhere to this rule should be marked as errors.\r\n\r\nExample of  the Transaction:\r\n\r\n- command ; Get\r\n- address[1:0] : 2'b1\r\n- size : 1\r\n- mask: 4'b0010\r\n\r\nThe transaction mentioned above should be marked as an error due to \r\nillegal size of mask.\r\n\r\nRTL behaves accordingly but the Testbench (TB) fails to detect the error.\r\nThe problem in the TB comes from [this constraint](https://cs.opensource.google/opentitan/opentitan/+/master:hw/dv/sv/tl_agent/tl_seq_item.sv;drc=820380a20267272e9b8b5e2fc2d041a8a32b7b74;l=16)\r\n\r\nDesired constraint should be\r\n   a_opcode != PutPartialData || $countones(a_mask) == (1 << a_size)\r\n\r\nHowever, implementing this desired constraint triggers other dependencies of the constraint, leading to broader failure in the Testbench.\r\nAs a result, addressing this constraint issue is currently put on hold until we can find a suitable solution that does not cause broader failures in the Testbench",
    "error_message": null,
    "module": "tlul",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TIMING",
    "root_cause": "invalid constraint in testbench",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "IP:tlul",
      "Earlgrey-PROD Candidate"
    ],
    "state": "closed",
    "created_at": "2023-07-21T15:25:00Z",
    "updated_at": "2024-06-03T11:41:00Z",
    "closed_at": "2024-06-03T11:41:00Z",
    "url": "https://github.com/lowRISC/opentitan/issues/19263",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/19263/comments"
  },
  {
    "bug_id": "OT-18905",
    "title": "[chip_test] Tests use unclaibrated clock to access otp",
    "description": "### Description\n\nFollowing tests using uncalibrated clock to write otp\r\n\r\n[chip_sw_lc_ctrl_volatile_raw_unlock](https://cs.opensource.google/opentitan/opentitan/+/master:hw/top_earlgrey/dv/chip_sim_cfg.hjson;drc=09b5d3521ea81900413c03ec2601acfc8d3eda85;l=862)\r\n[rom_volatile_raw_unlock](https://cs.opensource.google/opentitan/opentitan/+/master:hw/top_earlgrey/dv/chip_rom_tests.hjson;drc=18c3a74f991290e007728266677896b2c0f10ee0;l=870)\r\n\r\nNeed to update [sv sequence](https://cs.opensource.google/opentitan/opentitan/+/master:hw/top_earlgrey/dv/env/seq_lib/chip_sw_lc_volatile_raw_unlock_vseq.sv;drc=322190e3ab1c311f0b8af7cce437d8fef8636b6d;l=5)\r\nto have external clock before test does\r\n[otp_program](https://cs.opensource.google/opentitan/opentitan/+/master:hw/top_earlgrey/dv/env/seq_lib/chip_sw_lc_volatile_raw_unlock_vseq.sv;drc=322190e3ab1c311f0b8af7cce437d8fef8636b6d;l=63)\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TIMING",
    "root_cause": "driver or sequence issue",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2023-06-14T04:54:31Z",
    "updated_at": "2023-06-20T04:03:35Z",
    "closed_at": "2023-06-20T04:03:34Z",
    "url": "https://github.com/lowRISC/opentitan/issues/18905",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/18905/comments"
  },
  {
    "bug_id": "OT-18001",
    "title": "[flash_ctrl] scramble disable creates spurious fatal ecc error in hw_info",
    "description": "### Description\n\nSee #18000 for bug reproduce PR and command.\r\nThe test randomize hw_info_cfg_override register before flash init\r\nto test #16812\r\nWhen both registers are the same value, test will pass.\r\nBut if  hw_info_cfg_override.scramble_dis = MuBi4True and hw_info_cfg_override.ecc_dis = MuBi4False,\r\nrtl generates fatal error (ecc failure).",
    "error_message": "But if  hw_info_cfg_override.scramble_dis = MuBi4True and hw_info_cfg_override.ecc_dis = MuBi4False,\r\nrtl generates fatal error (ecc failure).",
    "module": "flash_ctrl",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "ecc injection or parity handling issue",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:flash_ctrl"
    ],
    "state": "closed",
    "created_at": "2023-04-17T06:44:56Z",
    "updated_at": "2023-04-19T03:31:05Z",
    "closed_at": "2023-04-19T03:31:05Z",
    "url": "https://github.com/lowRISC/opentitan/issues/18001",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/18001/comments"
  },
  {
    "bug_id": "OT-15607",
    "title": "[test-triage] [rv_dm] rv_dm_sba_tl_access",
    "description": "### Hierarchy of regression failure\n\nBlock level\n\n### Failure Description\n\n```\r\nTest rv_dm_sba_tl_access has 1 failures.\r\n7.rv_dm_sba_tl_access.2592420076\r\nLine 215, in log /container/opentitan-public/scratch/os_regression/rv_dm-sim-vcs/7.rv_dm_sba_tl_access/latest/run.log\r\n\r\n  UVM_ERROR @  11557104 ps: (rv_dm_scoreboard.sv:258) [uvm_test_top.env.scoreboard] Check failed data == sba_tl_item.a_data (X [0xXXXX5900] vs 2272876800 [0x87795900])\r\n  SBA item:\r\n  item: (sba_access_item@5307) { bus_op: BusOpWrite  size: SbaAccessSize8b  addr: 'he0aa6891  wdata: { [0]: 'hff877959  } readonaddr: 'hX  readondata: 'hX  autoincrement: 'h0  rdata: -  is_busy_err: 'h0  is_err: SbaErrNone  timed_out: 'h0  }\r\n  SBA TL item:\r\n  req: (cip_tl_seq_item@5273) { a_addr: 'he0aa6890  a_data: 'h87795900  a_mask: 'h2  a_size: 'h2  a_param: 'h0  a_source: 'h0  a_opcode: 'h1  a_user: 'h25497  d_param: 'h0  d_source: 'h0  d_data: 'h429b56f5  d_size: 'h2  d_opcode: 'h0  d_error: 'h0  d_sink: 'h0  d_user: 'h1cb3  a_source_is_overridden: 'h0  a_valid_delay: 'h0  d_valid_delay: 'h0  a_valid_len: 'h0  d_valid_len: 'h0  req_abort_after_a_valid_len: 'h0  rsp_abort_after_d_valid_len: 'h0  req_completed: 'h0  rsp_completed: 'h0  tl_intg_err_type: TlIntgErrNone  max_ecc_errors: 'h3  }\r\n```\r\n\r\nThis is a symptom of the fix made to DV_CHECK macros. \n\n### Steps to Reproduce\n\n- Commit hash where failure was observed\r\n- dvsim invocation command to reproduce the failure, inclusive of build and run seeds:\r\n  ./util/dvsim/dvsim.py hw/ip/rv_dm/dv/rv_dm_sim_cfg.hjson -i rv_dm_sba_tl_access --fixed-seed 2592420076  --waves -v h\n\n### Tests with similar or related failures\n\n- [ ] rv_dm_bad_sba_tl_access\r\n- [ ] rv_dm_autoincr_sba_tl_access\r\n\r\nFixes are needed in `sba_access_utils_pkg` code (both, the access utils as well as the monitor). \r\n",
    "error_message": "  SBA TL item:\r\n  req: (cip_tl_seq_item@5273) { a_addr: 'he0aa6890  a_data: 'h87795900  a_mask: 'h2  a_size: 'h2  a_param: 'h0  a_source: 'h0  a_opcode: 'h1  a_user: 'h25497  d_param: 'h0  d_source: 'h0  d_data: 'h429b56f5  d_size: 'h2  d_opcode: 'h0  d_error: 'h0  d_sink: 'h0  d_user: 'h1cb3  a_source_is_overridden: 'h0  a_valid_delay: 'h0  d_valid_delay: 'h0  a_valid_len: 'h0  d_valid_len: 'h0  req_abort_after_a_valid_len: 'h0  rsp_abort_after_d_valid_len: 'h0  req_completed: 'h0  rsp_completed: 'h0  tl_intg_err_type: TlIntgErrNone  max_ecc_errors: 'h3  }\r\n```\r\n\r",
    "module": "rv_dm",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "ecc injection or parity handling issue",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:rv_dm",
      "Component:TestTriage"
    ],
    "state": "closed",
    "created_at": "2022-10-20T07:05:58Z",
    "updated_at": "2022-10-21T04:43:30Z",
    "closed_at": "2022-10-21T04:43:29Z",
    "url": "https://github.com/lowRISC/opentitan/issues/15607",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/15607/comments"
  },
  {
    "bug_id": "OT-15606",
    "title": "[test-triage] [UART] uart_perf test",
    "description": "### Hierarchy of regression failure\n\nBlock level\n\n### Failure Description\n\n```\r\nJob uart-sim-vcs_run_default killed due to: Exit reason: User job exceeded runlimit: User job timed out has 5 failures:\r\nTest uart_perf has 5 failures.\r\n21.uart_perf.2259572504\r\nLog /container/opentitan-public/scratch/os_regression/uart-sim-vcs/21.uart_perf/latest/run.log\r\n\r\n  Job ID: smart:a8d28e98-4d9c-4946-94f9-78a7d88e044a\r\n28.uart_perf.3395448402\r\nLog /container/opentitan-public/scratch/os_regression/uart-sim-vcs/28.uart_perf/latest/run.log\r\n\r\n  Job ID: smart:6ba840c6-42d3-4557-963b-91e164cdbac8\r\n... and 3 more failures.\r\n```\n\n### Steps to Reproduce\n\n- Commit hash where failure was observed\r\n- dvsim invocation command to reproduce the failure, inclusive of build and run seeds:\r\n  ./util/dvsim/dvsim.py hw/ip/uart/dv/uart_sim_cfg.hjson -i uart_perf --fixed-seed 2259572504 --waves -v h\n\n### Tests with similar or related failures\n\nNA",
    "error_message": "Job uart-sim-vcs_run_default killed due to: Exit reason: User job exceeded runlimit: User job timed out has 5 failures:\r\nTest uart_perf has 5 failures.\r\n21.uart_perf.2259572504\r\nLog /container/opentitan-public/scratch/os_regression/uart-sim-vcs/21.uart_perf/latest/run.log\r\n\r\n  Job ID: smart:a8d28e98-4d9c-4946-94f9-78a7d88e044a\r\n28.uart_perf.3395448402\r\nLog /container/opentitan-public/scratch/os_regression/uart-sim-vcs/28.uart_perf/latest/run.log\r\n\r\n  Job ID: smart:6ba840c6-42d3-4557-963b-91e164cdbac8\r\n... and 3 more failures.",
    "module": "uart",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:uart",
      "Component:TestTriage"
    ],
    "state": "closed",
    "created_at": "2022-10-20T07:02:01Z",
    "updated_at": "2022-10-21T23:17:04Z",
    "closed_at": "2022-10-21T23:17:04Z",
    "url": "https://github.com/lowRISC/opentitan/issues/15606",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/15606/comments"
  },
  {
    "bug_id": "OT-15469",
    "title": "[edn] EDN doesn't support backpressure from CSRNG on RES/GEN commands",
    "description": "Factored out from #15402.\r\n\r\nWhile working on #14240 it has been noticed that EDN currently doesn't support backpressure from CSRNG when transmitting contents of the command FIFOs. As a result, whenever a RES/GEN command contains more than 1 word of additional data, word 2 and 3 are dropped by CSRNG which then keeps waiting for the last two words forever. Similarly, EDN keeps waiting for the final ACK of CSRNG. Both IPs lock up.\r\n\r\nThe waveform below shows this. `csrng_req_ready` goes low at the curser but EDN keeps updating the request bus `csrng_req_bus`. Words 1 and 2 of the seed (0x21CA8E3F and 0x5BA3DBA1) are not being picked up by CSRNG - they are missing in the `rdata_o` sequence at the bottom. `cmd_len_q` stays at 2 and CSRNG remains in the `SendMOP` state forever.\r\n\r\n![Screenshot from 2022-10-11 17-35-52](https://user-images.githubusercontent.com/20307557/195591306-e9b063f5-bc3d-43a1-9f7e-b17f8ee5ed24.png)\r\n\r\nI've worked out a first hot fix here #15402 but something more robust is needed. In addition also verification is needed for this feature.\r\n",
    "error_message": null,
    "module": "edn",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "MEMORY",
    "root_cause": "fifo pointer or full condition bug",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "Component:RTL",
      "IP:edn"
    ],
    "state": "closed",
    "created_at": "2022-10-13T12:08:56Z",
    "updated_at": "2022-10-24T09:59:47Z",
    "closed_at": "2022-10-24T09:59:47Z",
    "url": "https://github.com/lowRISC/opentitan/issues/15469",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/15469/comments"
  },
  {
    "bug_id": "OT-15451",
    "title": "[dv] X's in the operands of the pervasively used `DV_CHECK` macros results in an implicit check pass",
    "description": "Our `DV_CHECK_*` macros are defined here:\r\nhttps://github.com/lowRISC/opentitan/blob/d19d492fcac39fe201469b3935c9cb11c979d5a9/hw/dv/sv/dv_utils/dv_macros.svh#L85\r\n\r\nThey employ a negative check of the condition to throw an error when the condition is not met. \r\n```systemverilog\r\n  if (!(T_)) begin\r\n    // throw error\r\n  end\r\n```\r\nIf the expression `T_` evaluates to 'x' due to Xs in one of the operands in the expression `T_`, `!(T_)` also evaluates to 'x', which is treated as false. As a result, the `if` condition evaluates to false and the check is considered to have passed, because the error is not thrown. Consider the following scenario:\r\n```systemverilog\r\n  logic [31:0] foo;\r\n  foo = '0;\r\n  foo[0] = 1'bx;\r\n  `DV_CHECK_EQ(foo, '1)\r\n  // Expectation: check should fail because none of the bits of foo are 1. \r\n  // Reality: check passes just because the 0th bit is x. The rest of the bits are 0s. \r\n```\r\n\r\nIn the above example, ideally we should have used the case equality macro. However, in practice, we have rampantly used logical equality versions of the `DV_CHECK_*` macros throughout our codebase. Also, DV engineers tend to use the non-case equality version of the check macros when one of the operands is a fixed constant. \r\n\r\nA safer approach is to NOT use a negative check - instead use a positive check with error being thrown in the else clause. \r\n```systemverilog\r\n  if (T_) ; else begin\r\n    // throw error\r\n  end\r\n```\r\nWith this change, `DV_CHECK_EQ(foo, '1)` in the above example throws the error as expected. This makes `DV_CHECK` macros in line with an `assert` statement, because `assert` does a positive check, and throws an error thrown when the expression evaluates to false (i.e. the else clause). i.e., `assert(foo == '1)` throws an error because the expression evaluates to false and it goes into `else` block (in case of a missing else block, the tool throws an error with a generic message). In our assert macros, we specify an else block to print a custom message:\r\nhttps://github.com/lowRISC/opentitan/blob/d19d492fcac39fe201469b3935c9cb11c979d5a9/hw/ip/prim/rtl/prim_assert_standard_macros.svh#L10\r\n\r\nWe avoid using `assert` in DV code because it is sensitive to `$assertcontrol` statements.  \r\n\r\nWith this change, the macros will now pessimistically fail when the operand of the expressions contains an unknown bit, forcing the DV engineer to address it first (perhaps a missing reset, or not properly initialized, etc). \r\n\r\nThanks @eunchan for bringing this up!",
    "error_message": "systemverilog\r\n  if (!(T_)) begin\r\n    // throw error\r\n  end",
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "Milestone:V2"
    ],
    "state": "closed",
    "created_at": "2022-10-12T19:53:58Z",
    "updated_at": "2022-10-14T23:18:57Z",
    "closed_at": "2022-10-14T23:18:57Z",
    "url": "https://github.com/lowRISC/opentitan/issues/15451",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/15451/comments"
  },
  {
    "bug_id": "OT-15381",
    "title": "[entropy_src/dv] entropy_src environment cannot detect unnecessary drops",
    "description": "The `entropy_src` module drops output seeds frequently, because either the output is stalled and not pulling or occasionally because of certain exception conditions.   Since DV has little way of predicting many of these events, it is currently very lenient of missing seeds.  \r\n\r\nThis is however a problem if there is a bug that could cause seeds to drop indefinitely.  For example, consider the bug noticed in an attempted fix to #15257.  In the waveform below the  DUT ends up is supposed to suppress at most two bad seeds, on the grounds that their inputs are corrupted.   This version however has a bug in which all outputs are suppressed from the second this corruption condition is recognized, as the `fw_ov_corrupted` signal never clears.\r\n\r\n![image](https://user-images.githubusercontent.com/47870387/194935134-b12c3873-61ca-4cae-82df-e5c207e9a362.png)\r\n\r\nThis bug itself is not hard to fix, however it is alarming fact that similar bugs may not be caught in simulation. The scoreboard needs to maintain a count of dropped seeds, and check the queue of remaining seeds during the `check_phase`.   \r\n\r\n> original estimate 4\r\n> estimate 20\r\n> remaining 2023-04-19 2",
    "error_message": null,
    "module": "entropy_src",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "OTHER",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "IP:entropy_src"
    ],
    "state": "closed",
    "created_at": "2022-10-10T19:08:19Z",
    "updated_at": "2023-05-17T15:42:07Z",
    "closed_at": "2023-04-21T09:28:28Z",
    "url": "https://github.com/lowRISC/opentitan/issues/15381",
    "comments_count": 10,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/15381/comments"
  },
  {
    "bug_id": "OT-15157",
    "title": "[flash_ctrl] err_code.rd_err doesn't capture intg error in the middle of transaction",
    "description": "use #15143 \r\ncmd:\r\n./util/dvsim/dvsim.py ./hw/ip/flash_ctrl/dv/flash_ctrl_sim_cfg.hjson -i flash_ctrl_integrity -r 1 -s 1670833615 --waves\r\n\r\n@4312991.8ns\r\ntb.dut.u_eflash.gen_flash_cores[1].u_core.u_rd.intg_ecc_err_o\r\ntb.dut.u_eflash.gen_flash_cores[1].u_core.rd_err_o\r\ntb.dut.u_eflash.gen_flash_cores[1].u_core.rd_done_o\r\ntb.dut.u_reg_core.u_err_code_rd_err.qs[0:0]\r\n\r\nThis is ctrl read and read response. Integrity error is injected from the storage.\r\nIntg err also triggers rd_err but it cannot be captured in err_code.rd_err.\r\n",
    "error_message": null,
    "module": "flash_ctrl",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "PROTOCOL",
    "root_cause": "ecc injection or parity handling issue",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "IP:flash_ctrl",
      "Milestone:V2S"
    ],
    "state": "closed",
    "created_at": "2022-09-27T17:41:29Z",
    "updated_at": "2022-09-28T07:29:38Z",
    "closed_at": "2022-09-28T07:29:24Z",
    "url": "https://github.com/lowRISC/opentitan/issues/15157",
    "comments_count": 9,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/15157/comments"
  },
  {
    "bug_id": "OT-14974",
    "title": "[otbn,dv] Modelled RMA request behaviour is not matching vs RTL",
    "description": "Failures in `otbn_escalate` test comes from RMA request causing state change earlier in ISS than RTL. Also, it does not change the error bus which actually needs to be pointing at `bad_internal_state` error.\r\n\r\n> estimate 4\r\n> remaining 2022-09-19 2",
    "error_message": null,
    "module": "otbn",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:otbn",
      "Earlgrey-PROD Candidate"
    ],
    "state": "open",
    "created_at": "2022-09-16T14:07:57Z",
    "updated_at": "2025-01-14T11:12:10Z",
    "closed_at": null,
    "url": "https://github.com/lowRISC/opentitan/issues/14974",
    "comments_count": 8,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/14974/comments"
  },
  {
    "bug_id": "OT-14918",
    "title": "[chip dv] Do not use cfg.clk_rst_vif.wait_clks() to wait for clock cycles",
    "description": "We need to replace the `cfg.clk_rst_if.wait_clks()` invocations in our test sequences with the appropriate clk / rst monitor in `chip_if ` for example, `cfg.chip_vif.sys_clk_rst_if.wait_clks()`.\r\n\r\nThe reason for this is explained in this commit: https://github.com/lowRISC/opentitan/pull/14917/commits/bb2bb8abf3cefcb5bb0b25680b6c74051809e5cb\r\n\r\nPreviously, the `wait_clks` on this would wait on the external clock source, which was unsed in most tests, so it was incorrect all along. As of the commit above, the clock port of this interface is unconnected. The clock remains active to prevent breakages.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TIMING",
    "root_cause": "scoreboard or monitor mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "Type:Cleanup",
      "TOP:earlgrey",
      "Milestone:V2",
      "Earlgrey-PROD Candidate"
    ],
    "state": "open",
    "created_at": "2022-09-14T07:07:27Z",
    "updated_at": "2025-01-14T11:12:09Z",
    "closed_at": null,
    "url": "https://github.com/lowRISC/opentitan/issues/14918",
    "comments_count": 9,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/14918/comments"
  },
  {
    "bug_id": "OT-14914",
    "title": "[dv] spi_host_driver squashes end of flash transaction",
    "description": "With back-to-back SPI flash transactions using the new chip_if interface, the spi_host_driver can squash the end of the first transaction. While stepping through the simulation, CSB went high to end the first transaction, then immediately went low at the beginning of the next one. There was zero simulation time in the middle, causing the two transactions to merge into one.\r\n\r\nIn addition, it seems the check for X on I/Os is also incompatible with the spi_host_driver's current behavior, since it ends transactions by setting sio[0] to 1'bx, not 1'bz. Is this desired?\r\n\r\nCC @tjaychen @weicaiyang ",
    "error_message": null,
    "module": "spi_device",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "PROTOCOL",
    "root_cause": "driver or sequence issue",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:spi_device"
    ],
    "state": "closed",
    "created_at": "2022-09-14T05:13:11Z",
    "updated_at": "2022-09-20T03:17:58Z",
    "closed_at": "2022-09-20T03:17:58Z",
    "url": "https://github.com/lowRISC/opentitan/issues/14914",
    "comments_count": 4,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/14914/comments"
  },
  {
    "bug_id": "OT-14872",
    "title": "[test-triage] Nightly regression fallout due to #14776",
    "description": "Update: \r\nThe following tests are fixed and passing as of PR #14876:\r\n\r\nFixed in #14876:\r\n- chip_sw_uart_smoketest\r\n- chip_sw_uart_smoketest_signed\r\n- chip_sw_uart_tx_rx\r\n- chip_sw_uart_tx_rx_idx1\r\n- chip_sw_uart_tx_rx_idx2\r\n- chip_sw_uart_tx_rx_idx3\r\n- chip_sw_lc_walkthrough_dev\r\n- chip_sw_lc_walkthrough_prod\r\n- chip_sw_lc_walkthrough_prodend\r\n- chip_sw_lc_walkthrough_rma\r\n- chip_sw_lc_walkthrough_testunlocks\r\n- chip_jtag_csr_rw\r\n- chip_jtag_mem_access\r\n- chip_same_csr_outstanding\r\n- chip_csr_aliasing\r\n- chip_sw_lc_ctrl_program_error\r\n- chip_sw_alert_handler_escalation\r\n- chip_sw_alert_handler_entropy\r\n- chip_sw_usb_ast_clk_calib\r\n- chip_sw_pwrmgr_b2b_sleep_reset_req\r\n- chip_csr_mem_rw_with_rand_reset\r\n- chip_sw_sysrst_ctrl_outputs\r\n- chip_sw_sleep_pwm_pulses\r\n- chip_sw_clkmgr_external_clk_src_for_lc\r\n- chip_csr_rw\r\n- chip_csr_bit_bash\r\n- chip_sw_lc_ctrl_transition\r\n- chip_sw_pwrmgr_random_sleep_all_reset_reqs\r\n- chip_sw_pwrmgr_b2b_sleep_reset_req\r\n- chip_sw_uart_rand_baudrate\r\n\r\nFixed in #14917:\r\n- chip_sw_uart_tx_rx_alt_clk_freq\r\n- chip_sw_uart_tx_rx_alt_clk_freq_low_speed\r\n\r\nFixed in #14934:\r\n- chip_sw_spi_device_tx_rx\r\n\r\nFixed in #14946:\r\n- chip_sw_uart_smoketest_signed\r\n- chip_sw_sleep_pwm_pulses\r\n- chip_sw_spi_device_tx_rx\r\n\r\nDebug and fixes in progress:\r\n- chip_tap_straps_dev (SV sequence is broken - fix coming soon)\r\n- chip_tap_straps_prod (SV sequence is broken - fix coming soon)\r\n- chip_tap_straps_rma  (SV sequence is broken - fix coming soon)\r\n- chip_sw_gpio_smoketest (fix coming soon)\r\n- chip_sw_gpio (fix coming soon)\r\n\r\nNew failures as of 9/13: \r\n- chip_sw_pwrmgr_random_sleep_all_reset_reqs\r\n- chip_sw_alert_handler_reverse_ping_in_deep_sleep\r\n- chip_sw_all_escalation_resets",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "FUNCTIONAL",
    "root_cause": "missing or improper reset handling",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "Type:Cleanup",
      "TOP:earlgrey",
      "Milestone:V2",
      "Component:TestTriage"
    ],
    "state": "closed",
    "created_at": "2022-09-10T17:40:55Z",
    "updated_at": "2022-10-11T22:05:44Z",
    "closed_at": "2022-10-11T22:05:44Z",
    "url": "https://github.com/lowRISC/opentitan/issues/14872",
    "comments_count": 6,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/14872/comments"
  },
  {
    "bug_id": "OT-14636",
    "title": "[test] extract_sw_logs_db requires .rodata section",
    "description": "I ran into this while working on #14627. The test program added in that PR is very minimal and does not have a `.rodata` section because it doesn't need it. We, however, call `extract_sw_logs_db` for the `.rodata` section when building for `sim_dv` unconditionally which causes the following error:\n\n```\nError: .rodata section not found in bazel-out/k8-fastbuild-ST-2cc462681f62/bin/sw/device/silicon_creator/rom/e2e/rom_e2e_shutdown_exception_c_prog_sim_dv.elf\n```\n\nTo work around this for now, I added the following at the end of the`.rodata` section definition in `rom_ext_common.ld` so that the linker emits an empty `.rodata` section.\n```\n. = ALIGN(4);\n_rodata_end = .;\n```\n\n",
    "error_message": "I ran into this while working on #14627. The test program added in that PR is very minimal and does not have a `.rodata` section because it doesn't need it. We, however, call `extract_sw_logs_db` for the `.rodata` section when building for `sim_dv` unconditionally which causes the following error:\n\n```",
    "module": "unknown",
    "severity": "LOW",
    "priority": "P3",
    "bug_type": "FUNCTIONAL",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P3",
      "Type:Bug",
      "Milestone:V2",
      "Component:Rom/E2e/Task"
    ],
    "state": "closed",
    "created_at": "2022-08-29T19:59:50Z",
    "updated_at": "2022-09-30T10:41:56Z",
    "closed_at": "2022-09-11T22:55:55Z",
    "url": "https://github.com/lowRISC/opentitan/issues/14636",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/14636/comments"
  },
  {
    "bug_id": "OT-14223",
    "title": "[otbn,dv] Loop warps does not work for OTBN",
    "description": "Trying to do a loop warp in our current DV environment generates an count error from `prim_counter`. However, we assume it shouldn't at the ISS side. That results with mismatches. This can be reproduced by running:\r\n\r\n`util/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i otbn_sw_errs_fatal_chk --reseed=1 --tool=xcelium -w --fixed-seed=2654402148`\r\n\r\n@msfschaffner I think this behaviour might have started with commit https://github.com/lowRISC/opentitan/commit/0794cfc4a8c1a5cbcd8d94ae3d8664215185afbf so you might have an idea about this problem, please let me know if I can help with more details.",
    "error_message": "\r\n`util/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i otbn_sw_errs_fatal_chk --reseed=1 --tool=xcelium -w --fixed-seed=2654402148`\r\n\r\n@msfschaffner I think this behaviour might have started with commit https://github.com/lowRISC/opentitan/commit/0794cfc4a8c1a5cbcd8d94ae3d8664215185afbf so you might have an idea about this problem, please let me know if I can help with more details.",
    "module": "otbn",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:otbn"
    ],
    "state": "closed",
    "created_at": "2022-08-11T15:55:57Z",
    "updated_at": "2022-08-16T12:41:01Z",
    "closed_at": "2022-08-16T12:41:01Z",
    "url": "https://github.com/lowRISC/opentitan/issues/14223",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/14223/comments"
  },
  {
    "bug_id": "OT-13897",
    "title": "[rv_dm] CSR test failed",
    "description": "@sriyerg \r\n\r\nAs discussed, the RV_DM csr_rw test are failing in some seeds. The CI in this PR #13822 happens to get this error too.\r\nPlease take a look. Or let me know if it's OK to exclude checking the DMI CSR. I can make a PR to fix it.\r\n\r\n> * `UVM_ERROR (csr_utils_pkg.sv:435) [csr_utils::csr_rd_check] Check failed obs == exp (* [*] vs * [*]) Regname: jtag_dtm_ral.dmi` has 1 failures:\r\n>     * Test rv_dm_jtag_dtm_csr_rw has 1 failures.\r\n>         * 0.rv_dm_jtag_dtm_csr_rw.1\\\r\n>           Line 53, in log /azp/agent/_work/1/s/scratch/HEAD/rv_dm-sim-vcs/0.rv_dm_jtag_dtm_csr_rw/out/run.log\r\n> \r\n>                 UVM_ERROR @  12021752 ps: (csr_utils_pkg.sv:435) [csr_utils::csr_rd_check] Check failed obs == exp (0 [0x0] vs 164877131100 [0x2663715d5c]) Regname: jtag_dtm_ral.dmi\r\n>                 UVM_INFO @  12021752 ps: (uvm_report_catcher.svh:705) [UVM/REPORT/CATCHER]\r\n>                 --- UVM Report catcher Summary ---\r\n",
    "error_message": "UVM_ERROR (csr_utils_pkg.sv:435) [csr_utils::csr_rd_check] Check failed obs == exp (* [*] vs * [*]) Regname: jtag_dtm_ral.dmi` has 1 failures:",
    "module": "rv_dm",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "Component:CI",
      "IP:rv_dm"
    ],
    "state": "closed",
    "created_at": "2022-07-28T22:45:14Z",
    "updated_at": "2022-08-01T05:44:29Z",
    "closed_at": "2022-08-01T05:44:22Z",
    "url": "https://github.com/lowRISC/opentitan/issues/13897",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/13897/comments"
  },
  {
    "bug_id": "OT-13572",
    "title": "[aes] Forcing main/cipher core FSM signals sometimes doesn't trigger fatal alerts",
    "description": "@vogelpi \r\nif you look at PR #13571\r\nand run /util/dvsim/dvsim.py hw/ip/aes/dv/aes_masking_sim_cfg.hjson -i aes_control_fi -r 1 -t xcelium  -s=1108401101\r\n\r\nyou will see tb.dut.u_aes_core.u_aes_control.gen_fsm[2].gen_fsm_n.u_aes_control_fsm_i.u_aes_control_fsm.cipher_in_ready_i\r\nbegin forced  high - and the two other interfaces continuing on as usual - not fatal is asserted.\r\nthis is one of the signals in the list you wanted me to check.\r\n![image](https://user-images.githubusercontent.com/53917183/178275817-3675aad7-bccd-4f7b-8e3d-0ba27a7aff65.png)\r\n\r\n",
    "error_message": "you will see tb.dut.u_aes_core.u_aes_control.gen_fsm[2].gen_fsm_n.u_aes_control_fsm_i.u_aes_control_fsm.cipher_in_ready_i\r\nbegin forced  high - and the two other interfaces continuing on as usual - not fatal is asserted.\r\nthis is one of the signals in the list you wanted me to check.\r\n![image](https://user-images.githubusercontent.com/53917183/178275817-3675aad7-bccd-4f7b-8e3d-0ba27a7aff65.png)\r",
    "module": "aes",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:aes"
    ],
    "state": "closed",
    "created_at": "2022-07-11T13:32:31Z",
    "updated_at": "2022-11-04T10:57:55Z",
    "closed_at": "2022-11-04T10:57:55Z",
    "url": "https://github.com/lowRISC/opentitan/issues/13572",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/13572/comments"
  },
  {
    "bug_id": "OT-13344",
    "title": "[chip dv] Coverage collection criteria for blocks at the chip level is broken / incorrect",
    "description": "Taking clkmgr for example: \r\nhttps://reports.opentitan.org/hw/top_earlgrey/dv/latest/cov_report/mod349.html#inst_tag_19988\r\n\r\nIt indicates that the toggle coverage is enabled only on the TLUL ports, but not the other ports of clkmgr. At the chip level, ALL ports need to be covered. The rest show up as unreachable, which is incorrect. \r\n\r\nIt may be possible that the last change made to the coverage collection might have broken this. Hopefully the fix is simple. ",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "PROTOCOL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "TOP:earlgrey",
      "Milestone:V2"
    ],
    "state": "closed",
    "created_at": "2022-06-22T21:38:11Z",
    "updated_at": "2022-08-17T06:19:50Z",
    "closed_at": "2022-08-17T06:19:50Z",
    "url": "https://github.com/lowRISC/opentitan/issues/13344",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/13344/comments"
  },
  {
    "bug_id": "OT-12421",
    "title": "[dv,top] chip_sw_pwrmgr_main_power_glitch_reset test is failing",
    "description": "The test is marked as done on the \"DV test deliverables\" list but is failing on the dashboard from May 1st. ",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "TESTBENCH",
    "root_cause": "missing or improper reset handling",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "TOP:earlgrey"
    ],
    "state": "closed",
    "created_at": "2022-05-02T16:32:30Z",
    "updated_at": "2022-05-11T21:19:19Z",
    "closed_at": "2022-05-11T21:19:18Z",
    "url": "https://github.com/lowRISC/opentitan/issues/12421",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/12421/comments"
  },
  {
    "bug_id": "OT-12377",
    "title": "[dvsim] prints abbreviated usage to avoid issue with `argparse` and argument specification",
    "description": "argparser prefers and lists usage as:\r\n`dvsim.py [options] positional-arguments`\r\nbut then doesn't support it if the final option is of arbitrary length (it interprets positional args as part of the list of arbitrary length and complains that they're missing).\r\nIt's hard to make small changes to the usage message from argparser to either include the `--` to terminate the arbitrary length list or change the order.\r\nIt's also hard to make argparser identify the positional arguments correctly if written as shown in the usage.\r\n\r\nWe mostly document a workaround already, but not directly, but the described usage is repeated once more in OT, incorrectly in a script that suggests how to kick off a dvsim run after building artifacts.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "OTHER",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:Doc",
      "Component:DV",
      "Priority:P2",
      "Resolution:Wontfix",
      "Type:Bug",
      "Tool:dvsim"
    ],
    "state": "closed",
    "created_at": "2022-04-28T15:00:57Z",
    "updated_at": "2022-07-19T18:49:10Z",
    "closed_at": "2022-07-19T18:49:10Z",
    "url": "https://github.com/lowRISC/opentitan/issues/12377",
    "comments_count": 9,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/12377/comments"
  },
  {
    "bug_id": "OT-12364",
    "title": "[dv/flash_ctrl] Foundry CI failure",
    "description": "Weicai and I have been debugging the following failure in foundry:\r\n## Failure Buckets\r\n\r\n* `UVM_FATAL (dv_utils_pkg.sv:147) [csr_utils::mem_wr] Timeout waiting to csr_wr flash_ctrl_core_reg_block.prog_fifo (addr=*)` has 1 failures:\r\n    * Test flash_ctrl_smoke has 1 failures.\r\n        * 0.flash_ctrl_smoke.1\\\r\n          Line 87, in log /workspace/mnt/opentitan_private/scratch/master/flash_ctrl_wrapper-sim-vcs/0.flash_ctrl_smoke/out/run.log\r\n\r\n                UVM_FATAL @ 2018518563 ps: (dv_utils_pkg.sv:147) [csr_utils::mem_wr] Timeout waiting to csr_wr flash_ctrl_core_reg_block.prog_fifo (addr=0x0)\r\n                UVM_INFO @ 2018518563 ps: (uvm_report_catcher.svh:705) [UVM/REPORT/CATCHER]\r\n                --- UVM Report catcher Summary ---\r\n                \r\nDocumenting the debug progress here:\r\nIt turns out somehow when programming the `prog_fifo` from `core_tl_i`, only the write pointer moves forward, but read pointer does not move and stays at 0. This causes the timeout when we continuously write 4 items to the write fifo.\r\n\r\nWeicai also found that the last commit that can pass is:\r\n681caf26b503eb15b5e445aca27016a87b567df4byTimothy Chenat Apr 22 2022, 09:57 AM\r\n[flash_ctrl] Update the shadow alert assignment",
    "error_message": "\r\n* `UVM_FATAL (dv_utils_pkg.sv:147) [csr_utils::mem_wr] Timeout waiting to csr_wr flash_ctrl_core_reg_block.prog_fifo (addr=*)` has 1 failures:\r\n    * Test flash_ctrl_smoke has 1 failures.\r\n        * 0.flash_ctrl_smoke.1\\\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "MEMORY",
    "root_cause": "timeout waiting for response",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-04-28T00:13:50Z",
    "updated_at": "2022-04-28T16:21:06Z",
    "closed_at": "2022-04-28T16:21:06Z",
    "url": "https://github.com/lowRISC/opentitan/issues/12364",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/12364/comments"
  },
  {
    "bug_id": "OT-12232",
    "title": "[dv,full_chip,lc_clk_byp] Harden clkmgr_external_clk_src_for_lc",
    "description": "This test currently has no way to detect that the external clock is indeed being used for clk_io. One way to check\r\nis to force off the AST internally generated clk_io during the time when both lc_clk_byp_req and lc_clk_byp_ack\r\nare both On: if the external clock is not being used the test will freeze because the lc will get stuck.",
    "error_message": null,
    "module": "clkmgr",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TIMING",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:clkmgr",
      "Milestone:V2S"
    ],
    "state": "closed",
    "created_at": "2022-04-20T19:46:40Z",
    "updated_at": "2022-06-15T16:57:04Z",
    "closed_at": "2022-06-15T16:57:04Z",
    "url": "https://github.com/lowRISC/opentitan/issues/12232",
    "comments_count": 17,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/12232/comments"
  },
  {
    "bug_id": "OT-11629",
    "title": "[dv] Nightly test links to old dates are broken",
    "description": "All of the \"previous version\" links on the CHIP-level [test page](https://reports.opentitan.org/hw/top_earlgrey/dv/latest/results.html) result in 404s.\r\n\r\n@cindychip: I think you are usually in charge of \"care and feeding of the nightlies\"?",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "TESTBENCH",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Priority:P1",
      "Type:Bug",
      "Milestone:V3"
    ],
    "state": "closed",
    "created_at": "2022-03-23T11:08:29Z",
    "updated_at": "2022-05-13T22:31:46Z",
    "closed_at": "2022-05-13T22:22:02Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11629",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11629/comments"
  },
  {
    "bug_id": "OT-11607",
    "title": "[Tooling] Some FSM states are not categorized as FSM coverage",
    "description": "\r\nWe found some FSM states are not categorized as FSM coverage after doing some casting.\r\n\r\nFor example: In OTP_CTRL there is a reg `state_q` under LCI module:\r\nhttps://github.com/lowRISC/opentitan/blob/master/hw/ip/otp_ctrl/rtl/otp_ctrl_lci.sv#L138\r\nBut in coverage report:\r\nhttps://reports.opentitan.org/hw/ip/otp_ctrl/dv/latest/cov_report/mod98.html#inst_tag_833\r\nWe did not see any FSM coverage.\r\n\r\nI think it might related to how we cast it the `state_q`: https://github.com/lowRISC/opentitan/blob/master/hw/ip/otp_ctrl/rtl/otp_ctrl_lci.sv#L276\r\n\r\nWe would like to see if you have seen this before and know if there are any solutions to let the tool recognize it as a FSM coverage.\r\n\r\nTo run it with coverage: you can use\r\n ./util/dvsim/dvsim.py hw/ip/otp_ctrl/dv/otp_ctrl_sim_cfg.hjson -i otp_ctrl_smoke --reseed 1 -c\r\n\r\nThanks @cindychip for summarizing the issue above.\r\n\r\n@msfschaffner also found that simulators seem to have problems inferring FSMs if the state register is not coded in a behavioral always_ff block in the same hierarchy. This is a potential workaround #11580",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TESTBENCH",
    "root_cause": "coverage regression or config issue",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Priority:P2",
      "Type:Bug",
      "Milestone:V2S"
    ],
    "state": "closed",
    "created_at": "2022-03-22T18:47:10Z",
    "updated_at": "2022-06-28T19:09:06Z",
    "closed_at": "2022-06-28T19:09:05Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11607",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11607/comments"
  },
  {
    "bug_id": "OT-11526",
    "title": "SPI_HOST: DUT unresponsive with RX FIFO reads at the end when active = 0",
    "description": "For some of the seeds i find the below scenario.\r\n\r\nall tx transactions are sent.\r\nfinally any rx transactions are read out.\r\nwhile active = 0 and TB continue to read transactions from FIFO suddenly DUT is non responsive.\r\nI am polling for rxqd = 0 in status and timing out.\r\n\r\nsome example seeds:\r\nPR : https://github.com/lowRISC/opentitan/pull/11082\r\nutil/dvsim/dvsim.py hw/ip/spi_host/dv/spi_host_sim_cfg.hjson -i spi_host_event --waves --fixed-seed 2838982550\r\nutil/dvsim/dvsim.py hw/ip/spi_host/dv/spi_host_sim_cfg.hjson -i spi_host_performance --waves --fixed-seed 714456067\r\n\r\nI wandered too much in the design . I needs some debug insights on this.\r\nCould be a corner case as well.",
    "error_message": null,
    "module": "spi_host",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TIMING",
    "root_cause": "fifo pointer or full condition bug",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:spi_host"
    ],
    "state": "closed",
    "created_at": "2022-03-18T10:52:58Z",
    "updated_at": "2022-03-28T10:27:56Z",
    "closed_at": "2022-03-28T10:27:56Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11526",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11526/comments"
  },
  {
    "bug_id": "OT-11457",
    "title": "[rtl/rstmgr] Add regwen to sw_rst_ctrl_n",
    "description": "The generated CSR docs for rstmgr have no \"Register enable\" attribute for SW_RST_CTRL_N. This should be SW_RST_REGWEN instead. The lack of this attribute means the generated CSR tests cannot predict when a write won't succeed, which causes lots of failures.\r\n\r\nBut the failures were not showing up because we were excluding sw_rst_ctrl_n from generated CSR tests, until \r\nhttps://github.com/lowRISC/opentitan/pull/11444 re-enables them.",
    "error_message": null,
    "module": "rstmgr",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "csr read/write mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "Component:RTL",
      "IP:rstmgr"
    ],
    "state": "closed",
    "created_at": "2022-03-15T23:48:27Z",
    "updated_at": "2022-03-24T16:40:12Z",
    "closed_at": "2022-03-24T16:40:12Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11457",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11457/comments"
  },
  {
    "bug_id": "OT-11333",
    "title": "[flash_ctrl] Clarification Of Software Control of Flash Code Fetch",
    "description": "The Specification indicates \u2026\u2026\r\n\r\n----------------------------------------------------------------------------------------------------------------------------------\r\nSoftware control of flash code fetch.\r\n\r\nFlash Code Execution Handling\r\n\r\nFlash can be used to store both data and code. To support separate access priviledges between\r\ndata and code, the flash protocol controller provides EXEC for software control.\r\n\r\nIf software programs EXEC to 0xa26a38f7, code fetch from flash is allowed. If software programs\r\nEXEC to any other value, code fetch from flash results in an error.\r\n\r\nThe flash protocol controller distinguishes code / data transactions through the instruction\r\ntype attribute of the TL-UL interface.\r\n\r\nFLASH_CTRL.EXEC @ 0x14\r\nControls whether flash can be used for code execution fetches\r\nBits\tType\tReset\tName\tDescription\r\n31:0\trw\t0x0\tEN\r\nA value of 0xa26a38f7 allows flash to be used for code execution. Any other value prevents code\r\nexecution.\r\n\r\nSUMMARY\r\nEXEC != 0xa26a38f7, Read Data (MuBi4False-Data) - Allowed, Read Data (MuBi4True-Code) - Denied\r\nEXEC == 0xa26a38f7, Read Data (MuBi4False-Data) - Allowed, Read Data (MuBi4True-Code) - Allowed\r\n----------------------------------------------------------------------------------------------------------------------------------\r\n\r\nThere are three TL Interfaces in the DUT, as I understand it, these are used for the following purposes\r\n\r\ncore_tl \u2013 Used to configure the Flash, Initialise, set up, erase, program, read \r\nmem_tl \u2013 Used by Host for Code and Data\r\nprim_tl \u2013 Vendor Specific Interface \u2013 Not Tested Here\r\n\r\nQUESTION 1\r\nThe Flash Code Execution Handling (FLASH_CTRL.EXEC) feature is therefore only applicable to Host reads using the mem_tl interface?\r\n\r\nQUESTION 2\r\nThe Spec indicates that\r\n\r\n\u201cIf software programs EXEC to 0xa26a38f7, code fetch from flash is allowed. If software programs\r\nEXEC to any other value, code fetch from flash results in an error.\u201d\r\n\r\nWhat I have observed in testing so far, is that if a Code Fetch is disallowed, there appears to be no \u2018error\u2019 generated.  But what I do see is that the data that is returned under this scenario is ZERO.\r\n\r\nIs this the expected behaviour?\r\n\r\nAt the moment my test is failing because the current Scoreboard is expecting a data match on read, and it is not getting one.\r\n\r\nI will continue to investigate this and will post any updates that I have.\r\n \r\n",
    "error_message": null,
    "module": "flash_ctrl",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "PROTOCOL",
    "root_cause": "missing or improper reset handling",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "IP:flash_ctrl",
      "Milestone:V2S"
    ],
    "state": "closed",
    "created_at": "2022-03-09T12:12:07Z",
    "updated_at": "2022-03-29T07:43:18Z",
    "closed_at": "2022-03-29T07:43:10Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11333",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11333/comments"
  },
  {
    "bug_id": "OT-11279",
    "title": "[pwm/dv] pwm failing V2 tests, potential corner case.",
    "description": "There appears to be an intermittent failure occurring on V2 tests, this is occurring in approx 10% in 50 tests run.\r\n\r\nThe issue appears to be caused by the tlm fifo containing an uncompared item upon completion of the test.\r\n\r\nRelated PR: #11055   ",
    "error_message": null,
    "module": "pwm",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "MEMORY",
    "root_cause": "fifo pointer or full condition bug",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "IP:pwm",
      "Milestone:V2"
    ],
    "state": "closed",
    "created_at": "2022-03-07T10:02:31Z",
    "updated_at": "2022-04-25T07:45:41Z",
    "closed_at": "2022-04-25T07:45:41Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11279",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11279/comments"
  },
  {
    "bug_id": "OT-11144",
    "title": "[entropy_src, dv] Data integrity check failed when forcing esrng fifo write error",
    "description": "In PR #9888 when checking the esrng fifo write error, both the sfifo_esrng_full and sfifo_esrng_push should be high, but the data integrity check failed afterwards.\r\n![image](https://user-images.githubusercontent.com/83983643/156040503-4c79e117-444d-45db-9120-348e58626235.png)\r\n",
    "error_message": null,
    "module": "entropy_src",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "MEMORY",
    "root_cause": "fifo pointer or full condition bug",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "Subsystem:Entropy",
      "IP:entropy_src",
      "Milestone:V2"
    ],
    "state": "closed",
    "created_at": "2022-02-28T18:45:55Z",
    "updated_at": "2022-03-15T04:45:22Z",
    "closed_at": "2022-03-15T04:45:22Z",
    "url": "https://github.com/lowRISC/opentitan/issues/11144",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/11144/comments"
  },
  {
    "bug_id": "OT-10848",
    "title": "[flash_ctrl] Wrong page size in flash_ctrl C test ",
    "description": "The chip's test **chip_sw_flash_access** is running the method **test_basic_io** in the file **sw/device/tests/flash_ctrl_test.c** https://github.com/lowRISC/opentitan/blob/b1e181b4ff83e60f4ee3a567bf358721d5336ad8/sw/device/tests/flash_ctrl_test.c#L37\r\nIn this test, the **input page** and **output page** variables declared as arrays that should be in the size of 1 full page of the flash. \r\nThe flash pages actual size is **256 64bits** words, however this arrays defined as arrays of **32bits** integers which means their size should be **512**, while in fact is defined as **FLASH_WORDS_PER_PAGE** which is **256**.\r\nThis in turn causes the flash to only do the programs and reads in this test on the 1st half of the pages.\r\n\r\nThe definition of the array as arrays in the size of **FLASH_WORDS_PER_PAGE** of 32bits integers:\r\nhttps://github.com/lowRISC/opentitan/blob/b1e181b4ff83e60f4ee3a567bf358721d5336ad8/sw/device/tests/flash_ctrl_test.c#L81-L82\r\n\r\nThe definition of the **FLASH_WORDS_PER_PAGE** parameter in the test:\r\nhttps://github.com/lowRISC/opentitan/blob/b1e181b4ff83e60f4ee3a567bf358721d5336ad8/sw/device/tests/flash_ctrl_test.c#L27\r\n\r\nThe definition of the **flash_get_words_per_page** method in the file **sw/device/lib/flash_ctrl.c**\r\nhttps://github.com/lowRISC/opentitan/blob/b1e181b4ff83e60f4ee3a567bf358721d5336ad8/sw/device/lib/flash_ctrl.c#L270-L272\r\n\r\nThe definition of the **FLASH_CTRL_PARAM_WORDS_PER_PAGE** parameter to be 256 in the **flash_ctrl_regs.h**\r\n(I'm not sure where this file is actually defined in the environment)\r\n![image](https://user-images.githubusercontent.com/78012616/154062768-51044810-85f0-43e1-bd0e-4f3fd24b82e8.png)\r\n",
    "error_message": null,
    "module": "flash_ctrl",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "TESTBENCH",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "IP:flash_ctrl",
      "Milestone:V2",
      "Component:ChipLevelTest"
    ],
    "state": "closed",
    "created_at": "2022-02-15T13:09:57Z",
    "updated_at": "2022-11-03T05:39:25Z",
    "closed_at": "2022-11-03T05:39:25Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10848",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10848/comments"
  },
  {
    "bug_id": "OT-10714",
    "title": "[tooling, xcelium] Have Xcelium generated HTML coverage report provide a link directly to test ranking",
    "description": "Referenced from this comment from @weicaiyang in PR #7210: \r\nhttps://github.com/lowRISC/opentitan/pull/7210#issuecomment-875854438",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "coverage regression or config issue",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Type:Bug",
      "Milestone:V3",
      "Earlgrey-PROD Triaged"
    ],
    "state": "open",
    "created_at": "2022-02-09T05:46:09Z",
    "updated_at": "2025-01-14T11:12:09Z",
    "closed_at": null,
    "url": "https://github.com/lowRISC/opentitan/issues/10714",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10714/comments"
  },
  {
    "bug_id": "OT-10617",
    "title": "aes_csr tests failing",
    "description": "./util/dvsim/dvsim.py hw/ip/aes/dv/aes_sim_cfg.hjson -i aes_shadow_reg_errors_with_csr_rw -r 1 -t xcelium -s=627433368\r\n\r\nfails with the following message:\r\n\r\n> UVM_ERROR @  31296262 ps: (csr_utils_pkg.sv:432) [csr_utils::csr_rd_check] Check failed obs == exp (39297 [0x9981] vs 72067 [0x11983]) Regname: aes_reg_block.ctrl_shadowed \r\n\r\nI have made two observations - \r\n\r\n1.  the expected value does not match what is actually written to the CTRL reg. because the test does not expect the operation to be forced to 01 for illegal values\r\n2. the response is missing the FORCE_ZERO_MASKS bit\r\n\r\nstarting with the first issue:\r\n\r\nas expected the ctrl register is updated twice as required for shadow regs.\r\nthe first update is a partial write\r\naddress: 0x1E3E3F74\r\nMask:0x7\r\nData: F37599BB\r\nthe ctrl reg is only 17 bits so we can narrow it down to this\r\nthe data is then 199BB\r\nconverting this to the fields of the register\r\n```\r\n1      1  001     1  001  1011 10  11\r\n|      | |__|     | |__| |_______| |_|\r\n|      |   |      |   |        |    |_   illegal  operation  -> will map to 01\r\n|      |   |      |   |        |________  invalid mode will map to AES_NONE -> 10_000\r\n|      |   |      |   |______________ key_len 128         -> 001\r\n|      |   |      |__ _____________ sideload_en  -> 1\r\n|      |   |____________________  prng_reseed_rate ->001\r\n|      |_______________________ manual mode -> 1\r\n|___________________________ force_zero_mast -> 1\r\n```\r\nwith the updated values due to illegal values this turns into\r\n1 1001 1001 1000 0001 (0x19981) (expected was 0x19983)\r\n\r\nso Clearly the CSR test is not aware that an illegal operation will map to 01\r\n\r\nthe second write to CTRL is (**notice how the two values doesn't match - but no alert is thrown I assume this is because they are invalid and mapped to 0x20)**\r\naddress 1E3E3F74\r\ndata(17bits) 1993B\r\n```\r\n1      1  001     1  001  1011 10  11\r\n|      | |__|     | |__| |_______| |_|\r\n|      |   |      |   |        |    |_   illegal  operation  -> will map to 01\r\n|      |   |      |   |        |________  invalid mode will map to AES_NONE -> 10_000\r\n|      |   |      |   |______________ key_len 128         -> 001\r\n|      |   |      |__ _____________ sideload_en  -> 1\r\n|      |   |____________________  prng_reseed_rate ->001\r\n|      |_______________________ manual mode -> 1\r\n|___________________________ force_zero_mast -> 1\r\n```\r\nwith the updated values due to illegal values this turns into\r\n1 1001 1001 1000 0001 (0x19981) (expected was 0x19983)\r\n\r\nbut the read data is only 0x9981 (the force zero mask bit has somehow been reset?)\r\n![image](https://user-images.githubusercontent.com/53917183/152536116-49341c82-c450-412b-955b-c8f5879272b4.png)\r\n\r\n\r\n",
    "error_message": "1      1  001     1  001  1011 10  11\r\n|      | |__|     | |__| |_______| |_|\r\n|      |   |      |   |        |    |_   illegal  operation  -> will map to 01\r\n|      |   |      |   |        |________  invalid mode will map to AES_NONE -> 10_000\r\n|      |   |      |   |______________ key_len 128         -> 001\r\n|      |   |      |__ _____________ sideload_en  -> 1\r\n|      |   |____________________  prng_reseed_rate ->001\r\n|      |_______________________ manual mode -> 1\r\n|___________________________ force_zero_mast -> 1",
    "module": "aes",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "IP:aes",
      "Milestone:V2"
    ],
    "state": "closed",
    "created_at": "2022-02-04T13:26:52Z",
    "updated_at": "2022-10-21T13:33:31Z",
    "closed_at": "2022-10-21T13:33:31Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10617",
    "comments_count": 6,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10617/comments"
  },
  {
    "bug_id": "OT-10387",
    "title": "[AES] missing output",
    "description": "@vogelpi \r\nI am seeing some wierd behavior which happens quite seldom.\r\nbut every now and then when I reset the DUT and restart - the DUT seems to start correctly but then after a while goes to IDLE with no output having been produced.\r\nwhich the ENV detects as an error and clears the registers and tries again. \r\nbut it seems the AES is stuck in this mode where the output is never produced.\r\nthe light blue blocks on the address bus are status reads - you can see both status, and the actual idle_o going high after being busy for a while.\r\nbut the output_valid never goes high\r\n![image](https://user-images.githubusercontent.com/53917183/151259007-a9357aed-ba1e-477f-b0e3-e80ef6765002.png)\r\n\r\n\r\nunfortunately I have not found a failing seed on VCS \r\nso I suggest we spend a little time thursday figuring out what is happening.\r\n\r\n\r\n\r\n",
    "error_message": null,
    "module": "aes",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "IP:aes",
      "Milestone:V2"
    ],
    "state": "closed",
    "created_at": "2022-01-26T22:41:23Z",
    "updated_at": "2022-02-11T10:33:49Z",
    "closed_at": "2022-02-11T10:33:49Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10387",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10387/comments"
  },
  {
    "bug_id": "OT-10366",
    "title": "CS OTP: 2nd tl_agent on PRIM vif",
    "description": "A new tl_agent on PRIM TL-UL virtual interface was introduced in `otp_ctrl_env` and OS TB:\r\nhttps://github.com/lowRISC/opentitan/blob/93b72864a668a983f1db177512811c24681421f5/hw/ip/otp_ctrl/dv/env/otp_ctrl_env.sv#L67\r\nhttps://github.com/lowRISC/opentitan/blob/68e86515989c047e28915f6d5d534c578c9bdb3d/hw/ip/otp_ctrl/dv/tb.sv#L226\r\n\r\nHowever, there's already a tl_agent automatically created for the this vif in CS when CS RAL is integrated into the system.\r\nhttps://github.com/lowRISC/opentitan/blob/68e86515989c047e28915f6d5d534c578c9bdb3d/hw/dv/sv/cip_lib/cip_base_env_cfg.sv#L95\r\n\r\nThis creates a problem when accessing the CS RAL via frontdoor, since the new `prim_tl_agent.monitor` will fail because of a check on pending A channel requests, which was sent by `shim_tl_agent.driver` on the same prim vif but was not added to `pending_a_req` of `prim_tl_agent.monitor` since it wasn't the agent the request was sent through.\r\n\r\nhttps://github.com/lowRISC/opentitan/blob/68e86515989c047e28915f6d5d534c578c9bdb3d/hw/dv/sv/tl_agent/tl_monitor.sv#L199",
    "error_message": null,
    "module": "otp_ctrl",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "OTHER",
    "root_cause": "scoreboard or monitor mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug",
      "Component:OT_Blocks_Foundry",
      "IP:otp_ctrl"
    ],
    "state": "closed",
    "created_at": "2022-01-26T11:17:04Z",
    "updated_at": "2022-03-10T13:46:45Z",
    "closed_at": "2022-03-10T13:46:45Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10366",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10366/comments"
  },
  {
    "bug_id": "OT-10257",
    "title": "[dv/cip] Fix and document mubi randomization",
    "description": "The weights of true, false, and others should treat others as a group and be uniform.\r\nThe current scheme is flawed since it under-samples true and false.",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "OTHER",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-01-21T18:50:15Z",
    "updated_at": "2022-02-28T17:47:38Z",
    "closed_at": "2022-02-28T17:47:38Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10257",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10257/comments"
  },
  {
    "bug_id": "OT-10255",
    "title": "[usbdev] Fix smoke test",
    "description": ">estimate 160\r\n>From https://github.com/lowRISC/opentitan/issues/10255#issuecomment-1481647000",
    "error_message": null,
    "module": "usbdev",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "Hotlist:Silicon",
      "IP:usbdev",
      "Milestone:V1"
    ],
    "state": "closed",
    "created_at": "2022-01-21T17:57:00Z",
    "updated_at": "2023-06-15T15:59:25Z",
    "closed_at": "2023-06-15T15:59:24Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10255",
    "comments_count": 8,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10255/comments"
  },
  {
    "bug_id": "OT-10209",
    "title": "[rom_ctrl] Align ROM width to 40bit",
    "description": "We currently are experiencing issues in closed-source sims due to an SVA that fires due to width mismatches (the closed source uses an aligned ROM macro width of 40bit due to memory compiler limitations, whereas the open-source uses 39bit).\r\n\r\nWe determined that the easiest way to fix this would be to align the ROM to 40bit in opensource as well.\r\n\r\nImplementation wise there are multiple options: only make the physical width 40bit, but keep the logical width that the ROM controller operates on at 39bit, or align both to 40bit. I would say we do whatever is more convenient.\r\n\r\n@tjaychen do you remember where that issue was filed initially for reference?\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "MEMORY",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-01-20T02:32:48Z",
    "updated_at": "2022-02-04T09:56:04Z",
    "closed_at": "2022-02-04T00:37:27Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10209",
    "comments_count": 6,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10209/comments"
  },
  {
    "bug_id": "OT-10137",
    "title": "[dv] The #1ps delay in dut_init means we never start a sequence item on the first clock edge",
    "description": "This seems like a bad idea because \"valid is asserted on the first clock\" is the sort of situation that could trigger a HW bug.\r\n\r\nThis delay (in `dv_base_vseq::dut_init`) dates back to an old commit (6d31a7c). I think I managed to trigger the problem that it's trying to work around last night. We've got a task in the TL host driver called `flush_during_reset()`. When we're in reset, this pops and discards any sequence items that come in. Unfortunately, if a sequence item arrives at the same time as we come out of reset, you can end up in a situation where we kill the thread that was popping and discarding the items at the wrong point, leaving things out of whack and getting a UVM error.\r\n\r\nDo we actually need to discard TL items that arrive when we're in reset? If not, we could flush the queue as we go into reset (or 1ps after, if we're worried) and not have to worry about this synchronisation at all.\r\n\r\n@weicaiyang: I think you've looked at this code last? @sriyerg: Since you might have an opinion about whether this is something we need to worry about.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TIMING",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "Milestone:V3",
      "Earlgrey-PROD Candidate"
    ],
    "state": "open",
    "created_at": "2022-01-18T09:21:47Z",
    "updated_at": "2025-01-14T11:12:08Z",
    "closed_at": null,
    "url": "https://github.com/lowRISC/opentitan/issues/10137",
    "comments_count": 9,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10137/comments"
  },
  {
    "bug_id": "OT-10119",
    "title": "[dv,pwrmgr] Bogus indices in pwrmgr_rstmgr_sva_if assertions",
    "description": "These cause compilation warnings at chip-level like this:\r\n```\r\nWarning-[SIOB] Select index out of bounds\r\n../src/lowrisc_dv_pwrmgr_rstmgr_sva_if_0.1/pwrmgr_rstmgr_sva_if.sv, 97\r\n\"rstreqs[pwrmgr_pkg::ResetSwReqIdx]\"\r\n  The select index is out of declared bounds : [3:0].\r\n  In module instance : pwrmgr_rstmgr_sva_if pwrmgr_rstmgr_sva_if \r\n  In module : pwrmgr_rstmgr_sva_if.\r\n```\r\n\r\nThe problem seems to be that `rstreqs` is of type `logic[HwResetWidth-1:0]` and the SVA is assuming that it's of type `logic [TotalResetWidth-1:0]`. Looking at the code, it looks like we're getting bound in to RTL where the signal really is the narrower width, so I think the SVA is probably just wrong (or we're binding the interface in at the wrong place)\r\n\r\n@matutem: I think this is your code?",
    "error_message": "Warning-[SIOB] Select index out of bounds\r\n../src/lowrisc_dv_pwrmgr_rstmgr_sva_if_0.1/pwrmgr_rstmgr_sva_if.sv, 97\r\n\"rstreqs[pwrmgr_pkg::ResetSwReqIdx]\"\r\n  The select index is out of declared bounds : [3:0].\r\n  In module instance : pwrmgr_rstmgr_sva_if pwrmgr_rstmgr_sva_if \r\n  In module : pwrmgr_rstmgr_sva_if.",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-01-17T14:56:11Z",
    "updated_at": "2022-02-08T23:47:17Z",
    "closed_at": "2022-02-08T23:47:17Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10119",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10119/comments"
  },
  {
    "bug_id": "OT-10116",
    "title": "[dv,chip] Missing OTP_EXT_VOLT connection in top_earlgrey/dv/tb",
    "description": "This port was added to `chip_earlgrey_asic` in d13f442539 last April(!) and not connected up to the chip top-level testbench. This causes warnings when building the VCS simulation.\r\n\r\n@msfschaffner (since you added the port!); @sriyerg (for visibility, since this is a little worrying! Hopefully toggle coverage would have caught it eventually).",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "coverage regression or config issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-01-17T14:28:01Z",
    "updated_at": "2022-01-18T21:57:03Z",
    "closed_at": "2022-01-18T21:57:03Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10116",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10116/comments"
  },
  {
    "bug_id": "OT-10115",
    "title": "[dv,rstmgr] Missing ports when instantiating pwrmgr_rstmgr_sva_if in rstmgr_bind.sv",
    "description": "This shows up when building a chip-level test, but probably also comes up for rstmgr-only tests. Example VCS log entry:\r\n```\r\nWarning-[TFIPC] Too few instance port connections\r\n../src/lowrisc_dv_rstmgr_sva_0.1/rstmgr_bind.sv, 13\r\nrstmgr, \"pwrmgr_rstmgr_sva_if pwrmgr_rstmgr_sva_if( .clk_i (clk_i),  .rst_ni (rst_ni),  .rst_lc_req (pwr_i.rst_lc_req),  .rst_sys_req (pwr_i.rst_sys_req),  .ndm_sys_req (ndmreset_req_i),  .reset_cause (pwr_i.reset_cause),  .rst_lc_src_n (pwr_o.rst_lc_src_n),  .rst_sys_src_n (pwr_o.rst_sys_src_n));\"\r\n  The above instance has fewer port connections than the module definition.\r\n  Please use '+lint=TFIPC-L' to print out detailed information of unconnected \r\n  ports.\r\n```\r\n\r\nLooks like 029d20f forgot to update the bind file? (@matutem)",
    "error_message": "Warning-[TFIPC] Too few instance port connections\r\n../src/lowrisc_dv_rstmgr_sva_0.1/rstmgr_bind.sv, 13\r\nrstmgr, \"pwrmgr_rstmgr_sva_if pwrmgr_rstmgr_sva_if( .clk_i (clk_i),  .rst_ni (rst_ni),  .rst_lc_req (pwr_i.rst_lc_req),  .rst_sys_req (pwr_i.rst_sys_req),  .ndm_sys_req (ndmreset_req_i),  .reset_cause (pwr_i.reset_cause),  .rst_lc_src_n (pwr_o.rst_lc_src_n),  .rst_sys_src_n (pwr_o.rst_sys_src_n));\"\r\n  The above instance has fewer port connections than the module definition.\r\n  Please use '+lint=TFIPC-L' to print out detailed information of unconnected \r\n  ports.",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "missing or improper reset handling",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-01-17T14:03:46Z",
    "updated_at": "2022-02-08T17:53:03Z",
    "closed_at": "2022-02-08T17:53:02Z",
    "url": "https://github.com/lowRISC/opentitan/issues/10115",
    "comments_count": 4,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/10115/comments"
  },
  {
    "bug_id": "OT-9938",
    "title": "[dv] Keys generated by the sideload interface are only 256b wide, but OTBN needs 384b",
    "description": "The problem is that `key_sideload_item.sv` defines `key0` and `key1` like this:\r\n```systemverilog\r\n  rand bit [keymgr_pkg::KeyWidth-1:0] key0;\r\n  rand bit [keymgr_pkg::KeyWidth-1:0] key1;\r\n```\r\nwhere `keymgr_pkg.sv` has:\r\n```systemverilog\r\n  parameter int KeyWidth = 256;\r\n  // ...\r\n  parameter int OtbnKeyWidth = 384;\r\n```\r\n\r\nThe easiest fix is probably to expand `key_sideload_item`'s keys out to 384 bits and then just take the lower bits for other users.\r\n\r\n@prajwalaputtappa: Would you mind taking a look?",
    "error_message": "systemverilog\r\n  rand bit [keymgr_pkg::KeyWidth-1:0] key0;\r\n  rand bit [keymgr_pkg::KeyWidth-1:0] key1;",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "OTHER",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2022-01-07T18:09:50Z",
    "updated_at": "2022-04-06T15:40:05Z",
    "closed_at": "2022-04-06T15:40:04Z",
    "url": "https://github.com/lowRISC/opentitan/issues/9938",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/9938/comments"
  },
  {
    "bug_id": "OT-9932",
    "title": "run_seq_with_rand_reset_vseq  Generate unaligned register write",
    "description": "when running the `spi_host_csr_mem_rw_with_rand_reset`\r\nthe sequence generate a write request to a register which is in fact a FIFO. the address is unaligned so the TLUL adapter flags an error in the response.\r\n\r\nas can be seen in the wave below the TL UL address [1:0] is 2'b11\r\nwhich triggers the unaling error check in the reg adapter.\r\nis this expected behavior for this test? it looks like the register should behave as any other register.\r\n![image](https://user-images.githubusercontent.com/53917183/148555171-ff4aeca0-2510-4ef8-b854-884e65026ac9.png)\r\n\r\nrecreate sha b5eefa44470c62121d4556b349ef2709b7e69bce\r\n/util/dvsim/dvsim.py hw/ip/spi_host/dv/spi_host_sim_cfg.hjson -i spi_host_csr_mem_rw_with_rand_reset -r 1 -t xcelium -w=shm s=2930650901",
    "error_message": null,
    "module": "spi_host",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "PROTOCOL",
    "root_cause": "missing or improper reset handling",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "Type:Question",
      "IP:spi_host"
    ],
    "state": "closed",
    "created_at": "2022-01-07T14:08:20Z",
    "updated_at": "2022-05-16T20:48:14Z",
    "closed_at": "2022-05-16T20:48:14Z",
    "url": "https://github.com/lowRISC/opentitan/issues/9932",
    "comments_count": 10,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/9932/comments"
  },
  {
    "bug_id": "OT-9692",
    "title": "[otbn,dv] Cover groups for external CSR access don't take read vs. write into account",
    "description": "We've wired through the `access_type` parameter, but don't actually use it.\r\n\r\nAlso (while touching this): we should probably re-think some of the coverage points. In particular, we should probably expect to see things like writes to read-only registers.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "coverage regression or config issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-12-14T18:17:37Z",
    "updated_at": "2022-01-17T15:11:58Z",
    "closed_at": "2022-01-17T15:11:58Z",
    "url": "https://github.com/lowRISC/opentitan/issues/9692",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/9692/comments"
  },
  {
    "bug_id": "OT-9582",
    "title": "[otbn,dv] Mismatch in EDN requests between ISS and RTL",
    "description": "Reproducible with e0aa2c3bc (current HEAD). Command:\r\n```\r\nutil/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i otbn_multi --fixed-seed 3502729549 -w --run-only\r\n```\r\nOutput:\r\n```\r\n\"../src/lowrisc_dv_otbn_sim_0.1/tb.sv\", 264: tb.MatchingReqRND_A: started at 204071382ps failed at 204071382ps\r\n\tOffending '(tb.dut.u_otbn_core.edn_rnd_req_o == edn_rnd_req_model)'\r\n```\r\n\r\nEither we've messed up the modelling in this situation or there's an RTL bug for when we send out requests.\r\n\r\n@ctopal: Would you mind taking a look, since you implemented this feature in DV?",
    "error_message": "util/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i otbn_multi --fixed-seed 3502729549 -w --run-only",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-12-08T11:54:48Z",
    "updated_at": "2021-12-09T14:35:26Z",
    "closed_at": "2021-12-09T14:35:26Z",
    "url": "https://github.com/lowRISC/opentitan/issues/9582",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/9582/comments"
  },
  {
    "bug_id": "OT-9488",
    "title": "[otbn] Spurious trace entries after a reset",
    "description": "It seems that sometimes we get a stray trace entry that pops up just after coming up from reset (if we reset OTBN in the middle of an operation). For example, the following test fails on the current head of master (c1bd139):\r\n```\r\n$ util/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i otbn_reset --fixed-seed 4287681356\r\n```\r\nThis is causing failures in our nightly tests.\r\n\r\nWhat seems to be happening is that the MOD entry of the `ispr_read` flags is being set by the last instruction before the reset and then this is carrying over and being acted upon at the start of the next go:\r\n\r\n![image](https://user-images.githubusercontent.com/104845/144468689-9a26c404-80cb-4258-800a-a50197792fb7.png)\r\n\r\nThis seems to go back to us adding the prefetch stage in commit 0ac448acf.\r\n\r\n@GregAC: You wrote the tracer machinery in the first place so hopefully understand how it all works (unlike me!) Would you mind taking a look?",
    "error_message": "$ util/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i otbn_reset --fixed-seed 4287681356",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-12-02T17:06:06Z",
    "updated_at": "2022-01-31T10:40:24Z",
    "closed_at": "2022-01-31T10:40:24Z",
    "url": "https://github.com/lowRISC/opentitan/issues/9488",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/9488/comments"
  },
  {
    "bug_id": "OT-8904",
    "title": "[sw/dif] Add parameters in autogen difs",
    "description": "The dif of parameterized IPs need to hold the value of these parameters. For example, pwrmgr needs parameters to track both the number of reset requests it receives (2 for earlgrey), and the number of wakeups (6 for earlgrey). Rstmgr also needs the number of reset requests. Clkmgr may also have some parameters. I think the dif autogen flow should place these parameters in the generated dif.\r\n\r\nI am filing it as a bug since I recall some of these units had an (annoying) extra \"params\" argument for many functions, which was meant to contain this information. Perhaps this was removed in the autogen change.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TIMING",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Component:Software",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-10-26T23:58:47Z",
    "updated_at": "2021-10-27T06:05:15Z",
    "closed_at": "2021-10-27T06:05:15Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8904",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8904/comments"
  },
  {
    "bug_id": "OT-8755",
    "title": "[dif] Autogen dependency architecture does not match #8142.",
    "description": "The dependency architecture of the auto-genenerated DIFs does not match that described in #8142. Specifically, auto-generated C/C++ files, `dif_<ip>_autogen.c` and `dif_<ip>_autogen_unittest.cc`, should #include auto-generated header files, `dif_<ip>_autogen.h`, **_not_** manually implemented header files.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Component:Software",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-10-20T06:04:35Z",
    "updated_at": "2021-10-20T18:09:26Z",
    "closed_at": "2021-10-20T18:09:26Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8755",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8755/comments"
  },
  {
    "bug_id": "OT-8729",
    "title": "[usbdev] Low power wake up config is reset on low power entry",
    "description": "The chip level DV test is failing in nightly regressions. \r\nhttps://reports.opentitan.org/hw/top_earlgrey/dv/latest/results.html\r\n\r\nTo reproduce, run:\r\n```\r\n./util/dvsim/dvsim.py hw/top_earlgrey/dv/chip_sim_cfg.hjson -i chip_sw_pwrmgr_usbdev_wakeup --fixed-seed 1056321001 --waves fsdb \r\n```\r\n\r\nThe sw test is located at:\r\n`sw/device/tests/sim_dv/pwrmgr_usbdev_smoketest.c`\r\n\r\n![image](https://user-images.githubusercontent.com/46467186/137811722-ceb330dd-cf06-4a9a-b8d3-5d90bf4ba788.png)\r\n\r\nIf I am reading this right, then it looks like the pre-sleep CSR cfg enabling the wake up is lost because it is reset. The 'fake' suspend signal that is generated right before sleep is lost as well due to reset. ",
    "error_message": "./util/dvsim/dvsim.py hw/top_earlgrey/dv/chip_sim_cfg.hjson -i chip_sw_pwrmgr_usbdev_wakeup --fixed-seed 1056321001 --waves fsdb",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TESTBENCH",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-10-18T21:56:40Z",
    "updated_at": "2021-10-21T18:27:43Z",
    "closed_at": "2021-10-21T18:27:43Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8729",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8729/comments"
  },
  {
    "bug_id": "OT-8715",
    "title": "[usbdev,alert] Turning USBDEV clock off and back on results in sigint fault on outgoing alert",
    "description": "![image](https://user-images.githubusercontent.com/46467186/137604118-2844e9a0-0ed5-426d-9023-3c27bf6f7ec7.png)\r\n\r\nThis is the failing clkmgr_smoketest at the chip level:\r\nhttps://reports.opentitan.org/hw/top_earlgrey/dv/latest/results.html\r\n\r\nAll this test did (upto this point) was turn USB PERI clock off and back on as a part of the `test_gateable_clocks()` routine. \r\n\r\n```\r\nUVM_ERROR (cip_base_scoreboard.sv:184) scoreboard [scoreboard] alert usbdev_fatal_fault has unexpected signal int error has 1 failures:\r\n\r\nTest chip_sw_clkmgr_smoketest has 1 failures.\r\n0.chip_sw_clkmgr_smoketest.1809524465\r\nLine 385, in log /usr/local/google/home/chencindy/nightly_openTitan/master/chip_earlgrey_asic-sim-vcs/0.chip_sw_clkmgr_smoketest/out/run.log\r\n\r\n  UVM_ERROR @ 1634228736 ps: (cip_base_scoreboard.sv:184) uvm_test_top.env.scoreboard [uvm_test_top.env.scoreboard] alert usbdev_fatal_fault has unexpected signal int error\r\n  UVM_INFO @ 1634228736 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n  --- UVM Report Summary ---\r\n  \r\n  Quit count reached!\r\n```\r\n\r\nSteps to reproduce:\r\n```bash\r\n$ ./util/dvsim/dvsim.py hw/top_earlgrey/dv/chip_sim_cfg.hjson -i chip_sw_clkmgr_smoketest --seed 1809524465 --waves [fsdb]\r\n```\r\n\r\nFiling an issue preemptively assuming this is a bug. Further debug pending. ",
    "error_message": "```\r\nUVM_ERROR (cip_base_scoreboard.sv:184) scoreboard [scoreboard] alert usbdev_fatal_fault has unexpected signal int error has 1 failures:\r\n\r\nTest chip_sw_clkmgr_smoketest has 1 failures.\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TIMING",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-10-16T23:08:30Z",
    "updated_at": "2021-11-01T17:59:05Z",
    "closed_at": "2021-11-01T17:59:04Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8715",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8715/comments"
  },
  {
    "bug_id": "OT-8376",
    "title": "[dv] tl_intg_err test sequence disables scoreboard but reads and checks register values",
    "description": "OTBN has a STATUS register which switches value to \"locked\" if it there has been some sort of fatal error. The malformed writes generated by the `tl_intg_err` test cause such an error.\r\n\r\nThe predictor for the behaviour of the STATUS register lives in `otbn_scoreboard.sv` but this test sequence disables the scoreboard. However, it also runs the `csr_wr` sequence that has its own inbuilt scoreboard, checking the register values it reads against the register values it expects. Since the OTBN scoreboard is disabled, it's not able to fix up the expected register values and... boom!\r\n\r\nProbably the principled way to do this is to change the `en_scb` bit to only configure whether we run the evaluator (rather than the predictor) in the scoreboard. But that's probably a big change. Easier might be to disable register value checking in the parallel `csr_wr` sequence if we've turned off the predictor.\r\n\r\n@weicaiyang: I think this is probably your code?\r\n@sriyerg: Any comments on the general design? Do the suggestions above look sensible?",
    "error_message": "OTBN has a STATUS register which switches value to \"locked\" if it there has been some sort of fatal error. The malformed writes generated by the `tl_intg_err` test cause such an error.\r\n\r\nThe predictor for the behaviour of the STATUS register lives in `otbn_scoreboard.sv` but this test sequence disables the scoreboard. However, it also runs the `csr_wr` sequence that has its own inbuilt scoreboard, checking the register values it reads against the register values it expects. Since the OTBN scoreboard is disabled, it's not able to fix up the expected register values and... boom!\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-09-27T15:52:44Z",
    "updated_at": "2021-09-29T07:05:41Z",
    "closed_at": "2021-09-29T07:05:41Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8376",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8376/comments"
  },
  {
    "bug_id": "OT-8087",
    "title": "[otbn,dv] Most \"bad branches\" are taken",
    "description": "In `insn_bxx_cg`, the `eq_oob_cross` and `eq_neg_cross` crosses track whether a branch was taken and whether the destination was above the top of memory or negative, respectively.\r\n\r\nWe generate branches hitting these crosses with `BadBranch`, but seem to very rarely pick the direction that means the branch wasn't taken, which means ew miss some of the bins.",
    "error_message": null,
    "module": "otbn",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "MEMORY",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:otbn",
      "Milestone:V3"
    ],
    "state": "closed",
    "created_at": "2021-09-06T17:09:48Z",
    "updated_at": "2023-02-24T16:15:56Z",
    "closed_at": "2023-02-24T16:15:55Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8087",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8087/comments"
  },
  {
    "bug_id": "OT-8085",
    "title": "[otbn,dv] We don't seem to be triggering at_loop_end_cp for some jumps/branches",
    "description": "This persists even with 500 seeds, so needs a bit more investigation. We *should* be seeing it for each of `beq`, `bne`, `jal`, `jalr`, `loop` and `loopi`.\r\n\r\nMarking as a bug because I thought the `BadAtEnd` generator would be handling it.",
    "error_message": null,
    "module": "otbn",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "OTHER",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "IP:otbn",
      "Milestone:V3"
    ],
    "state": "closed",
    "created_at": "2021-09-06T17:03:57Z",
    "updated_at": "2023-02-24T16:18:08Z",
    "closed_at": "2023-02-24T16:18:08Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8085",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8085/comments"
  },
  {
    "bug_id": "OT-8081",
    "title": "[otbn,dv] We don't see coverage for JALR instructions with grs1 > 12",
    "description": "This could be a bug in the generator, but it looks rather suspicious. Have we messed up our reporting somehow?\r\n\r\nTo debug, look at e.g. `grs1_01101_cross` in `enc_i_cg`.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "coverage regression or config issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-09-06T16:56:59Z",
    "updated_at": "2021-10-27T11:43:19Z",
    "closed_at": "2021-10-27T11:43:19Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8081",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8081/comments"
  },
  {
    "bug_id": "OT-8068",
    "title": "[dv] tl_reg_adapater::bus2reg converts PutPartialData host writes to UVM_READ reg op",
    "description": "`tl_reg_adapter::bus2reg`, which converts bus transactions from TL-UL host/device to a `uvm_reg_bus_op` only converts bus transactions to `UVM_WRITE uvm_reg_bus_op` if `bus_item.a_opcode == PutFullData`.\r\n\r\nHowever, `PutPartialData` is also a write request on the TL-UL bus, but it seems to be converted into a `UVM_READ uvm_reg_bus_op`.\r\nhttps://github.com/lowRISC/opentitan/blob/d9dc048680d89bd630ffae673103509e28017709/hw/dv/sv/tl_agent/tl_reg_adapter.sv#L85\r\n\r\nShouldn't `PutPartialData` also be considered as an opcode which will be regarded as a write transaction and be converted by the adapter into a `UVM_WRITE uvm_reg_bus_op`?\r\n\r\nIn other words, shouldn't the condition above change into:\r\n`rw.kind    = bus_rsp.is_write() ? UVM_WRITE : UVM_READ;`",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "PROTOCOL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-09-04T18:59:10Z",
    "updated_at": "2021-09-07T13:48:39Z",
    "closed_at": "2021-09-07T13:48:39Z",
    "url": "https://github.com/lowRISC/opentitan/issues/8068",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/8068/comments"
  },
  {
    "bug_id": "OT-7942",
    "title": "[dv,pwrmgr_ast_sva_if] MainPdHandshakeOn_A assertion failing at the top level",
    "description": "This assertion is implemented here: \r\nhttps://github.com/lowRISC/opentitan/blob/f851c9ae04c5c411703d6792aa4471ab036ee01d/hw/ip/pwrmgr/dv/sva/pwrmgr_ast_sva_if.sv#L53\r\n\r\nWe bound these assertions to `pwrmgr` at the chip level too, but unfortunately, it started firing in the low power tests:\r\nhttps://reports.opentitan.org/hw/top_earlgrey/dv/latest/results.html (grep for MainPdHandshakeOn_A)\r\n\r\nThe assertion basically enforces that the `main_pok` output of AST always track the `main_pd_n` output of `pwrmgr`, and be no more than 10 slow clock cycles apart. At the chip level, however, the `main_pok` turns off less than a clock cycle after `main_pd_n` deasserts (i.e., pwrmgr requesting to enter low power). Based on AST modeling, the `main_pok` turns off [`MPPD_FDLY` amount of time, which is `1us` ](https://github.com/lowRISC/opentitan/blob/f851c9ae04c5c411703d6792aa4471ab036ee01d/hw/top_earlgrey/ip/ast/rtl/rglts_pdm_3p3v.sv#L66) when the low power entry request is received. This seems less, considering we are running the slow / AON clock at 200kHz (5us period). Filing an issue to confirm this is really right. \r\n\r\nThe assertion failure occurs because at the offending clock edge, the assertion detects a 1 on `main_pd_n` and expects the `main_pok` to follow (i.e., 1). But on that edge, `main_pd_n` is 0, and less than 1 AON cycle later, `main_pok` has also already dropped.\r\n\r\n![image](https://user-images.githubusercontent.com/46467186/130912778-966fd903-ab00-4f21-8411-03d8adcca6bd.png)\r\n\r\n\r\n",
    "error_message": "This assertion is implemented here: \r\nhttps://github.com/lowRISC/opentitan/blob/f851c9ae04c5c411703d6792aa4471ab036ee01d/hw/ip/pwrmgr/dv/sva/pwrmgr_ast_sva_if.sv#L53\r\n\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TIMING",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-08-26T06:46:16Z",
    "updated_at": "2022-01-12T19:02:03Z",
    "closed_at": "2022-01-12T19:02:03Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7942",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7942/comments"
  },
  {
    "bug_id": "OT-7902",
    "title": "[keymgr] last strb is 0 when LC turns off keymgr",
    "description": "@tjaychen \r\nusually `strb` is never 0 when the valid is high. We also have assertion to check that and I think KMAC TB probably never test the case that `strb` is valid with value 0.\r\n\r\nWhen LC turns off keymgr in the middle of an operation, we will see the last `strb` is set to 0.\r\n![Screen Shot 2021-08-24 at 10 54 44 AM](https://user-images.githubusercontent.com/49293026/130666192-58914373-3087-4323-84fd-a7efcdff6828.png)\r\n\r\nSince this interacts with KMAC, we probably can't test this corner scenario in chip-level. If we do want to have this case in the keymgr side, we may need to test it at KMAC block-level TB as well.\r\n\r\ncc @eunchan @udinator ",
    "error_message": "@tjaychen \r\nusually `strb` is never 0 when the valid is high. We also have assertion to check that and I think KMAC TB probably never test the case that `strb` is valid with value 0.\r\n\r\nWhen LC turns off keymgr in the middle of an operation, we will see the last `strb` is set to 0.\r",
    "module": "unknown",
    "severity": "CRITICAL",
    "priority": "P0",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Priority:P0",
      "Type:Bug",
      "Component:RTL"
    ],
    "state": "closed",
    "created_at": "2021-08-24T18:03:20Z",
    "updated_at": "2022-02-23T18:38:51Z",
    "closed_at": "2021-08-28T08:01:45Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7902",
    "comments_count": 12,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7902/comments"
  },
  {
    "bug_id": "OT-7809",
    "title": "[otbn,dv] Teach the ISS to match the side-effect behaviour in the RTL and add cover points to check",
    "description": "For all (possible) multi-cycle instructions, we are going to need to update the ISS so that it can expose register updates on cycles other than the first. We then need to reverse engineer the RTL to generate a spec. See [this comment](https://github.com/lowRISC/opentitan/pull/7655#issuecomment-901217329) from Greg explaining how the RTL works at the moment.\r\n\r\nI'm a little concerned that we wouldn't have spotted these mismatches without the conversation on that PR, so we should also add some cover points for faults at all possible points in multi-cycle instructions. For example, underflowing `x1` at the start of an `LW` or overflowing it at the end.\r\n\r\n> estimate 16\r\n> remaining 2021-09-20 4",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "MEMORY",
    "root_cause": "rtl logic mismatch with spec",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-08-18T15:40:20Z",
    "updated_at": "2021-09-24T10:23:21Z",
    "closed_at": "2021-09-24T10:23:21Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7809",
    "comments_count": 7,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7809/comments"
  },
  {
    "bug_id": "OT-7805",
    "title": "[otbn,rig] Model bug with updating known value after an increment",
    "description": "I am having an error and it seems like it is related to `BN.MOVR`. It picks 32 as an acceptable value (which causes the error). \r\n\r\n![Screenshot from 2021-08-18 11-09-10](https://user-images.githubusercontent.com/87007427/129883373-c3261f80-9062-4d4d-a779-40cd388826a7.png)\r\n\r\n \r\n`_pick_gpr_for_indirect_wdr` method is checking if the known value is great than 31 so that's why I am thinking we are not successful with updating the value. `update_for_bnmovr` under `model.py` is incrementing `grs` and `grd` while masking them with 31. So, in the case of 31+1, it flips back to 0 and the model thinks the value is now 0 (while the real value is actually 32).\r\n\r\nI am not sure if it's correct to think like this, so @rswarbrick if you can have a look at it, it would be really great.\r\n\r\nThanks!",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect mask constraint",
    "labels": [
      "Component:DV",
      "Type:Bug",
      "Type:Question"
    ],
    "state": "closed",
    "created_at": "2021-08-18T10:38:05Z",
    "updated_at": "2021-08-18T13:28:25Z",
    "closed_at": "2021-08-18T13:28:25Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7805",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7805/comments"
  },
  {
    "bug_id": "OT-7533",
    "title": "[dv] CI chip_csr_rw fails sporadically.",
    "description": "I am seeing the UVM_ERRORs on `chip_csr_rw` tests. Sometimes from alert_handler other times from the ibex.\r\n\r\n```\r\n* `UVM_ERROR (csr_utils_pkg.sv:490) [csr_utils::csr_rd_check] Check failed obs == exp (* [*] vs * [*]) Regname: chip_reg_block.alert_handler.alert_class_shadowed_*` has 1 failures:\r\n    * Test chip_csr_rw has 1 failures.\r\n        * 0.chip_csr_rw.1109578077\\\r\n          Line 185, in log chip_earlgrey_asic-sim-vcs/0.chip_csr_rw/out/run.log\r\n\r\n                UVM_ERROR @ 1186030000 ps: (csr_utils_pkg.sv:490) [csr_utils::csr_rd_check] Check failed obs == exp (0 [0x0] vs 2 [0x2]) Regname: chip_reg_block.alert_handler.alert_class_shadowed_11\r\n                UVM_INFO @ 1186030000 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n                --- UVM Report Summary ---\r\n                \r\n                Quit count reached!\r\n```\r\n\r\nOR\r\n\r\n```\r\n* `UVM_ERROR (csr_utils_pkg.sv:490) [csr_utils::csr_rd_check] Check failed obs == exp (* [*] vs * [*]) Regname: chip_reg_block.rv_core_ibex_cfg.nmi_state.wdog` has 1 failures:\r\n    * Test chip_csr_rw has 1 failures.\r\n        * 1.chip_csr_rw.1712561460\\\r\n          Line 184, in log chip_earlgrey_asic-sim-vcs/1.chip_csr_rw/out/run.log\r\n\r\n                UVM_ERROR @ 1260980000 ps: (csr_utils_pkg.sv:490) [csr_utils::csr_rd_check] Check failed obs == exp (1 [0x1] vs 0 [0x0]) Regname: chip_reg_block.rv_core_ibex_cfg.nmi_state.wdog\r\n                UVM_INFO @ 1260980000 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n                --- UVM Report Summary ---\r\n                \r\n                Quit count reached!\r\n\r\n```\r\n\r\n",
    "error_message": "* `UVM_ERROR (csr_utils_pkg.sv:490) [csr_utils::csr_rd_check] Check failed obs == exp (* [*] vs * [*]) Regname: chip_reg_block.alert_handler.alert_class_shadowed_*` has 1 failures:\r\n    * Test chip_csr_rw has 1 failures.\r\n        * 0.chip_csr_rw.1109578077\\\r\n          Line 185, in log chip_earlgrey_asic-sim-vcs/0.chip_csr_rw/out/run.log\r\n\r\n                UVM_ERROR @ 1186030000 ps: (csr_utils_pkg.sv:490) [csr_utils::csr_rd_check] Check failed obs == exp (0 [0x0] vs 2 [0x2]) Regname: chip_reg_block.alert_handler.alert_class_shadowed_11\r\n                UVM_INFO @ 1186030000 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n                --- UVM Report Summary ---\r\n                \r\n                Quit count reached!",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "csr read/write mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-07-29T23:29:05Z",
    "updated_at": "2021-07-29T23:40:00Z",
    "closed_at": "2021-07-29T23:32:00Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7533",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7533/comments"
  },
  {
    "bug_id": "OT-7399",
    "title": "[dv/cip_base_vseq] extract_common_csrs doesn't exrtact regs for more than a single RAL",
    "description": "`cip_base_vseq::extract_common_csrs` should loop over all the RALs in the environment and get their csrs:\r\nhttps://github.com/lowRISC/opentitan/blob/b3bc45b4a805b4e8d9fcca3c85e3d793ded19ffc/hw/dv/sv/cip_lib/seq_lib/cip_base_vseq.sv#L281-L282\r\n\r\nHowever, due to the way `dv_base_reg_block::get_dv_base_regs` is built, the reference queue passed to it will just get overriden with new values, so only the latest RAL's registers will be registered in `cip_base_vseq::all_csrs` queue.\r\nhttps://github.com/lowRISC/opentitan/blob/b3bc45b4a805b4e8d9fcca3c85e3d793ded19ffc/hw/dv/sv/dv_base_reg/dv_base_reg_block.sv#L48\r\n\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "csr read/write mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-07-21T11:20:49Z",
    "updated_at": "2021-07-21T13:41:27Z",
    "closed_at": "2021-07-21T13:27:07Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7399",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7399/comments"
  },
  {
    "bug_id": "OT-7289",
    "title": "[dvsim] KeyError: <SimCfg.SimCfg object at 0x7f16327f7700>",
    "description": "When running in GUI mode with more than one test I get the following error. (It works fine without `--gui``):\r\n\r\n```\r\n\u276f util/dvsim/dvsim.py hw/ip/otbn/dv/uvm/otbn_sim_cfg.hjson -i smoke --fixed-seed 1 --waves --gui\r\nINFO: [dvsim] [proj_root]: /home/philipp/src/opentitan\r\nINFO: [SimCfg] [scratch_path]: [otbn] [/home/philipp/src/opentitan/scratch/otbn-lc-escalate-routing/otbn-sim-vcs]\r\nWARNING: [SimCfg] In GUI mode, only one test is allowed to run. Picking otbn:0.otbn_smoke.1\r\n\r\n\r\n\r\n\r\n         [   legend    ]: [Q: queued, D: dispatched, P: passed, F: failed, K: killed, T: total]                                                                                             \r\nTraceback (most recent call last):\r\n  File \"util/dvsim/dvsim.py\", line 704, in <module>\r\n    main()\r\n  File \"util/dvsim/dvsim.py\", line 685, in main\r\n    results = cfg.deploy_objects()\r\n  File \"/home/philipp/src/opentitan/util/dvsim/FlowCfg.py\", line 382, in deploy_objects\r\n    return Scheduler(deploy, get_launcher_cls()).run()\r\n  File \"/home/philipp/src/opentitan/util/dvsim/Scheduler.py\", line 155, in run\r\n    changed = self._poll(hms) or timer.check_time()\r\n  File \"/home/philipp/src/opentitan/util/dvsim/Scheduler.py\", line 392, in _poll\r\n    self._enqueue_successors(item)\r\n  File \"/home/philipp/src/opentitan/util/dvsim/Scheduler.py\", line 238, in _enqueue_successors\r\n    for next_item in self._get_successors(item):\r\n  File \"/home/philipp/src/opentitan/util/dvsim/Scheduler.py\", line 283, in _get_successors\r\n    for next_item in self._scheduled[target][cfg]:\r\nKeyError: <SimCfg.SimCfg object at 0x7f16327f7700>\r\n```\r\n\r\n@sriyerg ",
    "error_message": "    for next_item in self._scheduled[target][cfg]:\r\nKeyError: <SimCfg.SimCfg object at 0x7f16327f7700>\r\n```\r\n\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-07-13T10:30:16Z",
    "updated_at": "2022-02-21T23:38:52Z",
    "closed_at": "2022-02-21T23:38:52Z",
    "url": "https://github.com/lowRISC/opentitan/issues/7289",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/7289/comments"
  },
  {
    "bug_id": "OT-6596",
    "title": "[dv/common] incorrect `has_unmapped_addr` calculation",
    "description": "This is a followup issue to #6594.\r\n\r\nCurrently inside of `cip_base_vseq__tl_errors.svh`, we determine whether a given RAL model has unmapped addresses by doing the following calculation:\r\n```systemverilog\r\nhas_unmapped_addr = csr_addr_mask[ral_name] > cfg.ral_models[ral_name].get_max_offset();\r\n```\r\n\r\nThis calculation assumes that the CSRs and memories inside of the RAL model are all contiguous (which is incorrect) and does not take internal address \"holes\" into account.\r\ne.g. KMAC has two memory address ranges of `0x400-0x5ff` and `0x800-0xfff` with an address mask of `0xfff`, but the above calculation will indicate that KMAC does not have any unmapped addresses, which is clearly incorrect.\r\n\r\nProposed solution is as follows:\r\n- Make `has_unmapped_addr` a field inside of `dv_base_reg_block`, which is a more sensible place for this sort of information\r\n- Perform a one-time calculation as the reg block is being built to create a queue of `addr_range_t` structs that contain information about all unmapped address ranges in the reg block (if any even exist), and use this information to set `has_unmapped_addr`",
    "error_message": "systemverilog\r\nhas_unmapped_addr = csr_addr_mask[ral_name] > cfg.ral_models[ral_name].get_max_offset();",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "MEMORY",
    "root_cause": "incorrect mask constraint",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-05-18T17:26:26Z",
    "updated_at": "2021-06-22T02:07:07Z",
    "closed_at": "2021-06-22T02:07:07Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6596",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6596/comments"
  },
  {
    "bug_id": "OT-6594",
    "title": "[dv/common] `tl_errors_vseq` assumes that unmapped addresses exist",
    "description": "Current inside of `cip_base_vseq__tl_errors.svh`, we randomly create error cases using a `randcase` as shown below:\r\n```systemverilog\r\nrandcase\r\n  1: tl_write_csr_word_unaligned_addr(ral_name);\r\n  1: tl_write_less_than_csr_width(ral_name);\r\n  1: tl_protocol_err(p_sequencer.tl_sequencer_hs[ral_name]);\r\n  // only run when unmapped addr exists\r\n  has_unmapped_addr: tl_access_unmapped_addr(ral_name);\r\n  // only run this task when there is a mem\r\n  has_mem: tl_write_mem_less_than_word(ral_name);\r\n  has_mem: tl_read_mem_err(ral_name);\r\nendcase\r\n```\r\n\r\nHowever, the first of these tasks (`tl_write_csr_word_unaligned_addr`) assumes that unmapped addresses exist as it constrains the target addresses to be outside any valid CSR addresses and memory address ranges.\r\nThis results in runtime constraint errors when running the tl_error vseq on an IP where every single address in the RAL memory is mapped (such as SRAM memory RAL model):\r\n```\r\nSolver failed when solving following set of constraints \r\n\r\n\r\nbit[31:0] csr_addr_mask[\"sram_ctrl_prim_reg_block\"] = 32'h1fffc;\r\nbit[31:0] loc_mem_ranges[0].start_addr = 32'h0;\r\nbit[31:0] loc_mem_ranges[0].end_addr = 32'h1ffff;\r\nrand bit[31:0] addr; // rand_mode = ON \r\n\r\nconstraint WITH_CONSTRAINT    // (from this) (constraint_mode = ON) (../src/lowrisc_dv_cip_lib_0/seq_lib/cip_base_vseq__tl_errors.svh:60)\r\n{\r\n   (!((addr & csr_addr_mask[\"sram_ctrl_prim_reg_block\"]) inside {[loc_mem_ranges[0].start_addr:loc_mem_ranges[0].end_addr]}));\r\n}\r\n\r\n```\r\n\r\nThere is a pretty simple fix for this issue - make these three tasks dependent on `has_unmapped_addr` as follows:\r\n```systemverilog\r\nrandcase\r\n  1: tl_write_less_than_csr_width(ral_name);\r\n  1: tl_protocol_err(p_sequencer.tl_sequencer_hs[ral_name]);\r\n  // only run when unmapped addr exists\r\n  has_unmapped_addr: tl_write_csr_word_unaligned_addr(ral_name);\r\n  has_unmapped_addr: tl_access_unmapped_addr(ral_name);\r\n  // only run this task when there is a mem\r\n  has_mem: tl_write_mem_less_than_word(ral_name);\r\n  has_mem: tl_read_mem_err(ral_name);\r\nendcase\r\n```",
    "error_message": "systemverilog\r\nrandcase\r\n  1: tl_write_csr_word_unaligned_addr(ral_name);\r\n  1: tl_write_less_than_csr_width(ral_name);\r\n  1: tl_protocol_err(p_sequencer.tl_sequencer_hs[ral_name]);\r\n  // only run when unmapped addr exists\r\n  has_unmapped_addr: tl_access_unmapped_addr(ral_name);\r\n  // only run this task when there is a mem\r\n  has_mem: tl_write_mem_less_than_word(ral_name);\r\n  has_mem: tl_read_mem_err(ral_name);\r\nendcase",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "PROTOCOL",
    "root_cause": "invalid constraint in testbench",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-05-18T17:16:23Z",
    "updated_at": "2021-06-22T02:07:25Z",
    "closed_at": "2021-06-22T02:07:25Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6594",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6594/comments"
  },
  {
    "bug_id": "OT-6503",
    "title": "[sw] DIF pwrmgr smoketest does not work in DV",
    "description": "It works in Verilator possibly due to its single clock system. In DV, the wakeup arrives before the WFI. \r\n\r\n![image](https://user-images.githubusercontent.com/46467186/117924580-d0ab3e00-b2aa-11eb-9809-d50cb1a06750.png)\r\n\r\nWorking on a fix for this. ",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TIMING",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-05-12T05:47:52Z",
    "updated_at": "2022-02-08T23:25:14Z",
    "closed_at": "2022-02-08T23:25:14Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6503",
    "comments_count": 4,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6503/comments"
  },
  {
    "bug_id": "OT-6495",
    "title": "[kmac] switching entropy modes",
    "description": "Hi Eunchan,\r\n\r\nThe small wave snippet shown below is from the start of a SHAKE128 test iteration, where I have just written the `CFG` CSR to switch from EDN to SW entropy - however, this happens in the middle of the EDN entropy refreshing request from the previously completed hash operation.\r\n\r\n![Screenshot from 2021-05-11 14-13-35](https://user-images.githubusercontent.com/16736281/117885891-4986a780-b263-11eb-9728-192dfa54b2e9.png)\r\n\r\nAs you can see even though the `mode_i` detects that the new entropy mode is from SW, the state machine remains in the EDN states.\r\nThis causes the first keccak round to block until EDN request returns, even though the SW entropy is immediately available.\r\n\r\nIs there any requirement that entropy mode can only be switched from EDN to SW once a refreshing operation has completed, or is this an issue in the design?\r\n\r\nThanks,\r\nUdi",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "ecc injection or parity handling issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-05-11T21:18:44Z",
    "updated_at": "2021-10-08T00:09:28Z",
    "closed_at": "2021-10-08T00:09:15Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6495",
    "comments_count": 11,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6495/comments"
  },
  {
    "bug_id": "OT-6335",
    "title": "[ci] Current master is broken (since commit ef717d9)",
    "description": "CI is broken at the moment because of a failing chip-level CSR test. To reproduce:\r\n```\r\nutil/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson --select-cfgs chip -i chip_csr_rw --fixed-seed=1\r\n```\r\n\r\nI'm taking a look now, but it's not completely obvious what's going wrong so I'm not sure whether I'll be able to fix things before the end of the day. If not, maybe a Google engineer could take a look (conveniently, there's a DV sync-up meeting in a minute, so I'll hand this over in person).",
    "error_message": "util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson --select-cfgs chip -i chip_csr_rw --fixed-seed=1",
    "module": "unknown",
    "severity": "CRITICAL",
    "priority": "P0",
    "bug_type": "TESTBENCH",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Priority:P0",
      "Type:Bug",
      "Component:CI"
    ],
    "state": "closed",
    "created_at": "2021-04-27T15:48:43Z",
    "updated_at": "2021-05-13T08:28:34Z",
    "closed_at": "2021-04-28T08:16:41Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6335",
    "comments_count": 9,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6335/comments"
  },
  {
    "bug_id": "OT-6295",
    "title": "[otbn] Regression failure: Offending '$stable(lsu_addr_i)'",
    "description": "The regression that ran at Saturday April 24 2021 02:36:14 UTC shows the following error:\r\n\r\n```\r\nOffending '$stable(lsu_addr_i)':\r\n\r\n    47.otbn_single.644070143\r\n\r\n      Line 51, in log /usr/local/google/home/chencindy/nightly_openTitan/master/otbn-sim-vcs/47.otbn_single/out/run.log\r\n          Offending '$stable(lsu_addr_i)'\r\n      UVM_ERROR @   4706788 ps: (otbn_lsu.sv:98) [ASSERT FAILED] LsuLoadAddrStable\r\n      UVM_INFO @   4706788 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n      --- UVM Report Summary ---\r\n\r\n```",
    "error_message": "The regression that ran at Saturday April 24 2021 02:36:14 UTC shows the following error:\r\n\r\n```\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-04-24T12:53:51Z",
    "updated_at": "2021-04-27T08:46:40Z",
    "closed_at": "2021-04-27T08:46:40Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6295",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6295/comments"
  },
  {
    "bug_id": "OT-6061",
    "title": "[dvsim] Ctrl-C now waits 10 seconds",
    "description": "If you start a dvsim run and immediately hit Ctrl-C, you'll see something like this:\r\n```\r\nINFO: [StatusPrinter]           [   legend    ]: [Q: queued, D: dispatched, P: passed, F: failed, K: killed, T: total]\r\nINFO: [StatusPrinter] 00:00:00  [    build    ]: [Q: 0, D: 1, P: 0, F: 0, K: 0, T: 1]   0%\r\n^CINFO: [Scheduler] Received SIGINT. Exiting gracefully. Send another to force immediate quit (but you may need to manually kill child processes)\r\nINFO: [StatusPrinter] 00:00:10  [    build    ]: [Q: 0, D: 0, P: 0, F: 0, K: 1, T: 1] 100%\r\nINFO: [StatusPrinter] 00:00:10  [     run     ]: [Q: 0, D: 0, P: 0, F: 0, K: 1, T: 1] 100%\r\nINFO: [FlowCfg] [results]: [chip]:\r\n\r\n```\r\n\r\nWe used to stop immediately, but it seems that recent changes to the scheduler/launcher/dispatcher (I'm not sure which bit) have broken things.\r\n\r\n@sriyerg: I think this was your change. Could you take a look and see whether there's something simple to fix things?",
    "error_message": "INFO: [StatusPrinter]           [   legend    ]: [Q: queued, D: dispatched, P: passed, F: failed, K: killed, T: total]\r\nINFO: [StatusPrinter] 00:00:00  [    build    ]: [Q: 0, D: 1, P: 0, F: 0, K: 0, T: 1]   0%\r\n^CINFO: [Scheduler] Received SIGINT. Exiting gracefully. Send another to force immediate quit (but you may need to manually kill child processes)\r\nINFO: [StatusPrinter] 00:00:10  [    build    ]: [Q: 0, D: 0, P: 0, F: 0, K: 1, T: 1] 100%\r\nINFO: [StatusPrinter] 00:00:10  [     run     ]: [Q: 0, D: 0, P: 0, F: 0, K: 1, T: 1] 100%\r\nINFO: [FlowCfg] [results]: [chip]:",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-04-12T11:47:35Z",
    "updated_at": "2021-04-22T16:49:00Z",
    "closed_at": "2021-04-22T16:49:00Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6061",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6061/comments"
  },
  {
    "bug_id": "OT-6060",
    "title": "[dvsim] Dubious csr_rw test dispatch for chip-level testing",
    "description": "If you run\r\n```\r\nutil/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson --select-cfgs chip -i chip_csr_rw --reseed 20\r\n```\r\nwith commit 1def47b then you'll run 20 tests (good!). But they get reported like this:\r\n```\r\n|  Milestone  |          Name           | Tests       |  Passing  |  Total  |  Pass Rate  |\r\n|:-----------:|:-----------------------:|:------------|:---------:|:-------:|:-----------:|\r\n|     V2      | tl_d_outstanding_access | chip_csr_rw |    12     |   20    |   60.00 %   |      \r\n|     V2      |   tl_d_partial_access   | chip_csr_rw |    12     |   20    |   60.00 %   |\r\n|     V2      |                         | **TOTAL**   |    24     |   40    |   60.00 %   |\r\n|             |                         | **TOTAL**   |    24     |   40    |   60.00 %   |\r\n\r\n```\r\n\r\nShould this command have actually run 40 tests (where two different \"name\"d tests each use the same sequence)? Or is there something wrong with how we're reporting things?\r\n\r\n@sriyerg: You can probably understand this the quickest: I suspect something's come a bit unstuck in dvsim.",
    "error_message": "util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson --select-cfgs chip -i chip_csr_rw --reseed 20",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "TESTBENCH",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-04-12T11:35:20Z",
    "updated_at": "2021-04-22T16:49:44Z",
    "closed_at": "2021-04-22T16:49:44Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6060",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6060/comments"
  },
  {
    "bug_id": "OT-6059",
    "title": "[dv] Failing chip-level csr_rw tests",
    "description": "Running 40 copies of this test with\r\n```\r\nutil/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson --select-cfgs chip -i chip_csr_rw --reseed 20\r\n```\r\non commit 1def47b gives a 60% pass rate.\r\n\r\nUnfortunately this gates updates to add the real guts of `rom_ctrl` (because seed 1, used in CI, happens to start failing). The failures mostly seem to be ASSERT_KNOWN checks, but there are some others too. Here's the output from dvsim, but with triple back-ticks replaced by `'''`.\r\n```\r\n|  Milestone  |          Name           | Tests       |  Passing  |  Total  |  Pass Rate  |\r\n|:-----------:|:-----------------------:|:------------|:---------:|:-------:|:-----------:|\r\n|     V2      | tl_d_outstanding_access | chip_csr_rw |    12     |   20    |   60.00 %   |\r\n|     V2      |   tl_d_partial_access   | chip_csr_rw |    12     |   20    |   60.00 %   |\r\n|     V2      |                         | **TOTAL**   |    24     |   40    |   60.00 %   |\r\n|             |                         | **TOTAL**   |    24     |   40    |   60.00 %   |\r\n\r\n## List of Failures\r\n\r\n**'RUN':** '0.chip_csr_rw.1073341232'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/0.chip_csr_rw/out/run.log<br>\r\n'''\r\nUVM_ERROR @ 631740000 ps: (csr_utils_pkg.sv:512) [csr_utils::csr_rd_check] Check failed obs == exp (1 [0x1] vs 0 [0x0]) Regname: chip_reg_block.adc_ctrl_aon.a\r\ndc_intr_status.oneshot\r\nUVM_INFO @ 631740000 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '1.chip_csr_rw.2496866621'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/1.chip_csr_rw/out/run.log<br>\r\n'''\r\nOffending '(!$isunknown(cio_pwrb_out_o))'\r\nUVM_ERROR @ 418103448 ps: (sysrst_ctrl.sv:211) [ASSERT FAILED] PwrbOKnown\r\nUVM_INFO @ 418103448 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '2.chip_csr_rw.1313242581'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/2.chip_csr_rw/out/run.log<br>\r\n'''\r\nUVM_ERROR @ 929267979 ps: (csr_utils_pkg.sv:512) [csr_utils::csr_rd_check] Check failed obs == exp (1 [0x1] vs 0 [0x0]) Regname: chip_reg_block.sysrst_ctrl_ao\r\nn.key_intr_status.key0_in_l2h\r\nUVM_INFO @ 929267979 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '6.chip_csr_rw.4218767708'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/6.chip_csr_rw/out/run.log<br>\r\n'''\r\nOffending '(!$isunknown(irq_o))'\r\nUVM_ERROR @ 708400000 ps: (rv_plic.sv:381) [ASSERT FAILED] IrqKnownO_A\r\nUVM_INFO @ 708400000 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '7.chip_csr_rw.2445407989'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/7.chip_csr_rw/out/run.log<br>\r\n'''\r\nOffending '(!$isunknown(irq_o))'\r\nUVM_ERROR @ 745819978 ps: (rv_plic.sv:381) [ASSERT FAILED] IrqKnownO_A\r\nUVM_INFO @ 745819978 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '9.chip_csr_rw.2083772333'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/9.chip_csr_rw/out/run.log<br>\r\n'''\r\nUVM_ERROR @ 732574041 ps: (csr_utils_pkg.sv:512) [csr_utils::csr_rd_check] Check failed obs == exp (128 [0x80] vs 0 [0x0]) Regname: chip_reg_block.sysrst_ctrl_aon.key_intr_status\r\nUVM_INFO @ 732574041 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '10.chip_csr_rw.2136213087'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/10.chip_csr_rw/out/run.log<br>\r\n'''\r\nOffending '(!$isunknown(cio_pwrb_out_o))'\r\nUVM_ERROR @ 1147765080 ps: (sysrst_ctrl.sv:211) [ASSERT FAILED] PwrbOKnown\r\nUVM_INFO @ 1147765080 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n\r\n**'RUN':** '19.chip_csr_rw.741276314'<br>\r\n**LOG:** /src/lr/opentitan/scratch/HEAD/chip_earlgrey_asic-sim-vcs/19.chip_csr_rw/out/run.log<br>\r\n'''\r\nOffending '(!$isunknown(cio_key2_out_o))'\r\nUVM_ERROR @ 563469144 ps: (sysrst_ctrl.sv:214) [ASSERT FAILED] Key2OKnown\r\nUVM_INFO @ 563469144 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER]\r\n--- UVM Report Summary ---\r\n'''\r\n```",
    "error_message": "util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson --select-cfgs chip -i chip_csr_rw --reseed 20",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-04-12T11:26:56Z",
    "updated_at": "2021-04-14T14:53:45Z",
    "closed_at": "2021-04-14T14:53:44Z",
    "url": "https://github.com/lowRISC/opentitan/issues/6059",
    "comments_count": 2,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/6059/comments"
  },
  {
    "bug_id": "OT-5679",
    "title": "[otbn] RIG can generate instruction streams that depend on the state of flags before setting them",
    "description": "At the moment, the RIG is careful to only use registers and memory that have architectural values. The spec doesn't say that flags are cleared on start, so we should make sure not to do things like issue `csrrw` instructions to read the flags before they will have a value.\r\n\r\nThis meant that the generated binary triggered #5655. Alternatively, we might decide to specify that registers and CSRs are all cleared when starting an operation. If we do that, we need to remove the \"has an architectural value\" tracking from registers in the RIG.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "MEMORY",
    "root_cause": "csr read/write mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-03-18T16:43:52Z",
    "updated_at": "2021-03-22T15:02:24Z",
    "closed_at": "2021-03-22T15:02:24Z",
    "url": "https://github.com/lowRISC/opentitan/issues/5679",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/5679/comments"
  },
  {
    "bug_id": "OT-5493",
    "title": "[otbn] Failing \"single\" test in nightlies",
    "description": "The `single_binary` test failed on Sunday 7th March. Figure out why.\r\n\r\n```\r\n'RUN': '0.otbn_single.3020303980'\r\nLOG: /edascratch/chencindy-opentitan/nightly_openTitan/master/otbn-sim-vcs/0.otbn_single/out/run.log\r\n\r\nOffending '(!err)'\r\nUVM_ERROR @   3023421 ps: (otbn_model_if.sv:47) [ASSERT FAILED] NoModelErrs\r\nUVM_INFO @   3023421 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER] \r\n--- UVM Report Summary ---\r\n```",
    "error_message": "'RUN': '0.otbn_single.3020303980'\r\nLOG: /edascratch/chencindy-opentitan/nightly_openTitan/master/otbn-sim-vcs/0.otbn_single/out/run.log\r\n\r\nOffending '(!err)'\r\nUVM_ERROR @   3023421 ps: (otbn_model_if.sv:47) [ASSERT FAILED] NoModelErrs\r\nUVM_INFO @   3023421 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER] \r\n--- UVM Report Summary ---",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-03-08T14:31:43Z",
    "updated_at": "2021-03-19T12:44:17Z",
    "closed_at": "2021-03-19T12:44:17Z",
    "url": "https://github.com/lowRISC/opentitan/issues/5493",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/5493/comments"
  },
  {
    "bug_id": "OT-5492",
    "title": "[otbn] Failing nightly CSR tests",
    "description": "These are failing sporadically at the moment. Figure out what's going on and fix it (probably just a missing tag).\r\n\r\nAn example:\r\n```\r\n'RUN': '0.otbn_csr_mem_rw_with_rand_reset.1261978375'\r\nLOG: /edascratch/chencindy-opentitan/nightly_openTitan/master/otbn-sim-vcs/0.otbn_csr_mem_rw_with_rand_reset/out/run.log\r\n\r\nOffending '$onehot({a_inc_bignum, a_wlen_word_inc_bignum, b_inc_bignum, d_inc_bignum})'\r\nUVM_ERROR @ 387051851 ps: (otbn_decoder.sv:955) [ASSERT FAILED] BignumRegIncReq\r\nUVM_INFO @ 387051851 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER] \r\n--- UVM Report Summary ---\r\n```",
    "error_message": "'RUN': '0.otbn_csr_mem_rw_with_rand_reset.1261978375'\r\nLOG: /edascratch/chencindy-opentitan/nightly_openTitan/master/otbn-sim-vcs/0.otbn_csr_mem_rw_with_rand_reset/out/run.log\r\n\r\nOffending '$onehot({a_inc_bignum, a_wlen_word_inc_bignum, b_inc_bignum, d_inc_bignum})'\r\nUVM_ERROR @ 387051851 ps: (otbn_decoder.sv:955) [ASSERT FAILED] BignumRegIncReq\r\nUVM_INFO @ 387051851 ps: (uvm_report_server.svh:901) [UVM/REPORT/SERVER] \r\n--- UVM Report Summary ---",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "incorrect assertion or check macro",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2021-03-08T14:30:19Z",
    "updated_at": "2021-03-19T14:16:19Z",
    "closed_at": "2021-03-19T14:16:19Z",
    "url": "https://github.com/lowRISC/opentitan/issues/5492",
    "comments_count": 0,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/5492/comments"
  },
  {
    "bug_id": "OT-4427",
    "title": "Sim: tlul_assert: SVA errors - QSTA UART Smoke test",
    "description": "UART Smoke test on Questa now throws UVM_ERROR from SVA.\r\n\r\nI will debug later, any hints on where to start (from Design/protocol perspective, tool/SVA I can manage).\r\n\r\nAny remote chances of the (by now) infamous ADDR_WIDTH causing this?\r\n\r\nThanks\r\nSrini\r\n\r\n```log\r\n# UVM_INFO @    185530 ps: (../src/lowrisc_dv_tl_agent_0/tl_host_driver.sv:123) uvm_test_top.env.m_tl_agent.driver [uvm_test_top.env.m_tl_agent.driver] Req sent: a_addr = 0xe53e8b4c a_data = 0x2af30087 a_mask = 0xf a_size = 0x2 a_param = 0x0 a_source = 0xe9 a_opcode = PutFullData d_data = 0xa5f48578 d_size = 0x1 d_param = 0x0 d_source = 0xf6 d_opcode = AccessAckData d_error = 0 d_user = 100010110011111 d_sink = 1 req_abort_after_a_valid_len = 0 rsp_abort_after_d_valid_len = 0 req_completed = 1 rsp_completed = 0 \r\n# UVM_INFO @    185530 ps: (../src/lowrisc_dv_tl_agent_0/tl_monitor.sv:89) uvm_test_top.env.m_tl_agent.monitor [tl_logging] [][a_chan] : a_addr = 0xe53e8b4c a_data = 0x2af30087 a_mask = 0xf a_size = 0x2 a_param = 0x0 a_source = 0xe9 a_opcode = PutFullData d_data = 0x0 d_size = 0x0 d_param = 0x0 d_source = 0x0 d_opcode = AccessAck d_error = 0 d_user = 0 d_sink = 0 req_abort_after_a_valid_len = 0 rsp_abort_after_d_valid_len = 0 req_completed = 0 rsp_completed = 0 \r\n# UVM_ERROR @    185530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    195530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    205530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    215530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    220530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:238) [ASSERT FAILED] pendingReqPerSrc_M\r\n# UVM_INFO @    225530 ps: (../src/lowrisc_dv_tl_agent_0/tl_host_driver.sv:194) uvm_test_top.env.m_tl_agent.driver [uvm_test_top.env.m_tl_agent.driver] Got response a_addr = 0xe53e8b4c a_data = 0x2af30087 a_mask = 0xf a_size = 0x2 a_param = 0x0 a_source = 0xe9 a_opcode = PutFullData d_data = 0x0 d_size = 0x2 d_param = 0x0 d_source = 0xe9 d_opcode = AccessAck d_error = 0 d_user = 0 d_sink = 0 req_abort_after_a_valid_len = 0 rsp_abort_after_d_valid_len = 0 req_completed = 1 rsp_completed = 0 , pending req:0\r\n\r\n```\r\n",
    "error_message": "log\r\n# UVM_INFO @    185530 ps: (../src/lowrisc_dv_tl_agent_0/tl_host_driver.sv:123) uvm_test_top.env.m_tl_agent.driver [uvm_test_top.env.m_tl_agent.driver] Req sent: a_addr = 0xe53e8b4c a_data = 0x2af30087 a_mask = 0xf a_size = 0x2 a_param = 0x0 a_source = 0xe9 a_opcode = PutFullData d_data = 0xa5f48578 d_size = 0x1 d_param = 0x0 d_source = 0xf6 d_opcode = AccessAckData d_error = 0 d_user = 100010110011111 d_sink = 1 req_abort_after_a_valid_len = 0 rsp_abort_after_d_valid_len = 0 req_completed = 1 rsp_completed = 0 \r\n# UVM_INFO @    185530 ps: (../src/lowrisc_dv_tl_agent_0/tl_monitor.sv:89) uvm_test_top.env.m_tl_agent.monitor [tl_logging] [][a_chan] : a_addr = 0xe53e8b4c a_data = 0x2af30087 a_mask = 0xf a_size = 0x2 a_param = 0x0 a_source = 0xe9 a_opcode = PutFullData d_data = 0x0 d_size = 0x0 d_param = 0x0 d_source = 0x0 d_opcode = AccessAck d_error = 0 d_user = 0 d_sink = 0 req_abort_after_a_valid_len = 0 rsp_abort_after_d_valid_len = 0 req_completed = 0 rsp_completed = 0 \r\n# UVM_ERROR @    185530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    195530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    205530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    215530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:281) [ASSERT FAILED] dReadyKnown_A\r\n# UVM_ERROR @    220530 ps: (../src/lowrisc_tlul_common_0.1/rtl/tlul_assert.sv:238) [ASSERT FAILED] pendingReqPerSrc_M\r\n# UVM_INFO @    225530 ps: (../src/lowrisc_dv_tl_agent_0/tl_host_driver.sv:194) uvm_test_top.env.m_tl_agent.driver [uvm_test_top.env.m_tl_agent.driver] Got response a_addr = 0xe53e8b4c a_data = 0x2af30087 a_mask = 0xf a_size = 0x2 a_param = 0x0 a_source = 0xe9 a_opcode = PutFullData d_data = 0x0 d_size = 0x2 d_param = 0x0 d_source = 0xe9 d_opcode = AccessAck d_error = 0 d_user = 0 d_sink = 0 req_abort_after_a_valid_len = 0 rsp_abort_after_d_valid_len = 0 req_completed = 1 rsp_completed = 0 , pending req:0",
    "module": "unknown",
    "severity": "LOW",
    "priority": "P3",
    "bug_type": "PROTOCOL",
    "root_cause": "scoreboard or monitor mismatch",
    "labels": [
      "Component:DV",
      "Priority:P3",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-12-04T19:07:25Z",
    "updated_at": "2022-03-25T00:32:32Z",
    "closed_at": "2022-03-25T00:32:32Z",
    "url": "https://github.com/lowRISC/opentitan/issues/4427",
    "comments_count": 10,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/4427/comments"
  },
  {
    "bug_id": "OT-3383",
    "title": "[TLUL agent] Support to drop VALID without READY",
    "description": "According to TL spec, we need to have these 2 supports, which are not implemented in our agent\r\n1. VALID can't be dropped even READY is low (I'm already working on this)\r\n2. sender can change the contents of transition when it's not accepted, and we only consider receiver accept the item when both VALID and READY are high.\r\n\r\n> Note that a sender may raise valid and then lower it on the following cycle, even if the message was\r\n> not accepted on the previous cycle. For example, the sender might have some other higher priority\r\n> task to perform on the following cycle, instead of trying to send the rejected message again.\r\n> Furthermore, the sender may change the contents of the control and data signals when a message\r\n> was not accepted.\r\n\r\n> If ready is LOW, the receiver must not process the beat and the sender must not consider the\r\nbeat processed.\r\n\r\nRelated to #3354",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "PROTOCOL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-09-08T19:07:02Z",
    "updated_at": "2021-02-09T19:44:37Z",
    "closed_at": "2021-02-09T19:44:36Z",
    "url": "https://github.com/lowRISC/opentitan/issues/3383",
    "comments_count": 4,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/3383/comments"
  },
  {
    "bug_id": "OT-3303",
    "title": "[dv: tl ul] Host agent is not comforming to spec - back2back messages",
    "description": "in conjunction with #3208 \r\n\r\nWhile the TL-UL specification does not allow multi beat messages, I cannot find anything in the spec that disallows driving single beat messages back2back.\r\nwhich would give a burst-like behavior.\r\n\r\nCurrently, our DV host does not support this functionality. the minimum distance between consecutive messages is 1 clock cycle gap. This basically cuts the bandwidth in half.\r\n\r\nfigure 4.1 in  the specification version 1.8.1\r\n![image](https://user-images.githubusercontent.com/53917183/91723902-c887f400-eb9c-11ea-9648-53a889a1e2a3.png)\r\n\r\n> Message J has opcode 4, which on Channel A indicates a Get. Even though the Get operates on 16\r\nbytes as indicated by a_size, message J itself carries no data and thus fits in a single beat which is\r\naccepted immediately. Message K can then be issued and accepted the following cycle\r\n\r\n in the wave below the request is accepted immediately, so the next beat should be presented in the next cycle. but this is not the case\r\n![image](https://user-images.githubusercontent.com/53917183/91724126-20265f80-eb9d-11ea-9d51-251c667a5781.png)\r\n\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "TIMING",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-08-31T13:18:37Z",
    "updated_at": "2021-01-12T18:58:17Z",
    "closed_at": "2021-01-12T18:58:17Z",
    "url": "https://github.com/lowRISC/opentitan/issues/3303",
    "comments_count": 19,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/3303/comments"
  },
  {
    "bug_id": "OT-3299",
    "title": "AES DPI - VCS fixes",
    "description": "OS: CentOS 7\r\nTool: VCS\r\n\r\nAES - latest code uses DPI and I had to add the following to VCS compile to get it running:\r\n\r\n -CFLAGS \"-std=c99 -I../../../model -I/usr/include/openssl11/ -lssl -lcrypto\" \\\r\n-LDFLAGS \"-lssl -lcrypto \" \\\r\n\r\nI guess LDFLAGS is enough for -lssl -lcrypto (and not CFLAGS, though didn't try)\r\n\r\nIs this known issue? \r\n\r\nThanks\r\nSrini",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TESTBENCH",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-08-30T08:26:49Z",
    "updated_at": "2021-01-21T13:14:39Z",
    "closed_at": "2021-01-21T13:14:39Z",
    "url": "https://github.com/lowRISC/opentitan/issues/3299",
    "comments_count": 18,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/3299/comments"
  },
  {
    "bug_id": "OT-3208",
    "title": "[dv: tl ul] Host agent is not comforming to spec on request",
    "description": "According to the TL UL specification 1.8.0 on p24\r\nWen ever the host wants to make a request is must also be able to receive a response in the same cycle.\r\n\r\n> For example, a designer might be tempted to implement a master interface which holds d ready\r\nLOW while a valid is HIGH in order to delay a concurrent response message until the following\r\ncycle. However, this represents an indefinite delay on Channel D that is not allowed by any of the\r\nforward progress ready rules. Indeed, a TL-UL\u2013conforming slave interface may have connected\r\nd valid and d ready to a valid and a ready respectively. Thus, the non-conforming master\r\ninterface has introduced a deadlock.\r\n\r\n![image](https://user-images.githubusercontent.com/53917183/90800763-61a14a00-e315-11ea-8fa5-9175f00053d2.png)\r\n\r\nour host is clearly not respecting this.\r\n\r\n![image](https://user-images.githubusercontent.com/53917183/90801070-bc3aa600-e315-11ea-89dd-ffcfba827d3b.png)\r\n\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "TIMING",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-08-20T16:50:34Z",
    "updated_at": "2021-01-27T18:08:16Z",
    "closed_at": "2021-01-27T18:08:16Z",
    "url": "https://github.com/lowRISC/opentitan/issues/3208",
    "comments_count": 39,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/3208/comments"
  },
  {
    "bug_id": "OT-2968",
    "title": "[otbn] elf loading non-functional for standalone OTBN sim",
    "description": "When building a binary using otbn-as directly supplying the elf file as initial memory contents for the IMem in the standalone simulation doesn't seem to work. You need to produce a .vmem from the .elf with objcopy and srec_cat.\r\n\r\n> estimate 4",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "MEMORY",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-07-24T11:37:08Z",
    "updated_at": "2020-08-03T11:03:45Z",
    "closed_at": "2020-07-30T16:36:57Z",
    "url": "https://github.com/lowRISC/opentitan/issues/2968",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/2968/comments"
  },
  {
    "bug_id": "OT-2422",
    "title": "Wave dumping broken on xcelium",
    "description": "PR #2128 (mine) merged the VCS and xcelium code for dumping waves. This was probably a bad idea, because the two tools have different syntax. We need to split the code out again, either into a file per tool or a \"base\" file with an xcelium \"override\".\r\n\r\nTo get things working locally in the meantime, manually prefix the calls to `fsdb*` in waves.tcl with \"`call `\". The [original report](https://github.com/lowRISC/opentitan/pull/2128#discussion_r436205818) was inline in the PR that broke things.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "OTHER",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-06-08T07:26:51Z",
    "updated_at": "2022-08-29T17:55:50Z",
    "closed_at": "2022-08-29T17:55:50Z",
    "url": "https://github.com/lowRISC/opentitan/issues/2422",
    "comments_count": 7,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/2422/comments"
  },
  {
    "bug_id": "OT-2305",
    "title": "[dvsim] Listing regressions fails with \"Substitution for the wildcard \"UVM_HOME\" not found\"",
    "description": "```\r\n$ util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson  --list regressions\r\nERROR: [utils] Substitution for the wildcard \"UVM_HOME\" not found\r\n$ util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson  --list tests\r\nERROR: [utils] Substitution for the wildcard \"UVM_HOME\" not found\r\n```\r\n\r\nRunning the sanity regression works through dvsim, so it's not a general problem.",
    "error_message": "$ util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson  --list regressions\r\nERROR: [utils] Substitution for the wildcard \"UVM_HOME\" not found\r\n$ util/dvsim/dvsim.py hw/top_earlgrey/dv/top_earlgrey_sim_cfgs.hjson  --list tests\r\nERROR: [utils] Substitution for the wildcard \"UVM_HOME\" not found\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "unstable test environment or seed issue",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-05-22T09:50:54Z",
    "updated_at": "2020-05-28T18:42:41Z",
    "closed_at": "2020-05-28T18:42:41Z",
    "url": "https://github.com/lowRISC/opentitan/issues/2305",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/2305/comments"
  },
  {
    "bug_id": "OT-1770",
    "title": "[i2c dv] i2c_csr_hw_reset test failing with seed 1232859461",
    "description": "Here's the failure signature:\r\n```\r\nxmsim: *E,ASRTST (/edascratch/sriyer-opentitan/scratch/i2c.sim.xcelium/chip-csr-tests/default/src/lowrisc_ip_i2c_0.1/rtl/i2c.sv,92): (time 102138256 PS) \r\nAssertion tb.dut.CioSdaEnKnownO_A has failed \r\nUVM_ERROR @ 102138256 ps: (prim_assert.sv:18) [ASSERT FAILED] [tb.dut] CioSdaEnKnownO_A (/edascratch/sriyer-opentitan/scratch/i2c.sim.xcelium/chip-csr-tests/default/src/lowrisc_ip_i2c_0.1/rtl/i2c.sv:92)\r\n```\r\n\r\nThis is a rare random seed that is failing. Please kindly debug and provide a fix. \r\n\r\nHere's the step to reproduce the error with waves:\r\n```console\r\n$ ./util/dvsim.py hw/ip/i2c/dv/i2c_sim_cfg.hjson -i i2c_csr_hw_reset --reseed 1 --seed 1232859461 --waves --v h --job-prefix <wd-job-prefix>\r\n```",
    "error_message": "xmsim: *E,ASRTST (/edascratch/sriyer-opentitan/scratch/i2c.sim.xcelium/chip-csr-tests/default/src/lowrisc_ip_i2c_0.1/rtl/i2c.sv,92): (time 102138256 PS) \r\nAssertion tb.dut.CioSdaEnKnownO_A has failed \r\nUVM_ERROR @ 102138256 ps: (prim_assert.sv:18) [ASSERT FAILED] [tb.dut] CioSdaEnKnownO_A (/edascratch/sriyer-opentitan/scratch/i2c.sim.xcelium/chip-csr-tests/default/src/lowrisc_ip_i2c_0.1/rtl/i2c.sv:92)\r\n```\r",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-03-17T01:44:32Z",
    "updated_at": "2022-08-17T06:31:29Z",
    "closed_at": "2022-08-17T06:31:29Z",
    "url": "https://github.com/lowRISC/opentitan/issues/1770",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/1770/comments"
  },
  {
    "bug_id": "OT-1696",
    "title": "[AES DV] Sanity test is failing",
    "description": "AES Sanity test is currently failing at HEAD. \r\n```\r\nxmsim: *E,RNDCNSTE (scratch/aes.sim.xcelium/dvsim-err-on-exit/default/src/lowrisc_dv_aes_env_0.1/aes_seq_item.sv,68|20): Randomization constraint has this error, which will cause the randomize function to return 0 and no new rand values will be set:\r\nUnsupported operator 'VST_E_LAST_ELEMENT' in this constraint expression.\r\n      data_in_queue[$][31:8]   == 0;\r\n                    |\r\nxmsim: *E,RNDCNSTE (scratch/aes.sim.xcelium/dvsim-err-on-exit/default/src/lowrisc_dv_aes_env_0.1/aes_seq_item.sv,68|20): Randomization constraint has this error, which will cause the randomize function to return 0 and no new rand values will be set:\r\nUnsupported datatype in constraint.\r\n    `DV_CHECK_RANDOMIZE_WITH_FATAL(aes_item, key_size == 3'b001;)\r\n                                                                |\r\nxmsim: *W,SVRNDF (scratch/aes.sim.xcelium/dvsim-err-on-exit/default/src/lowrisc_dv_aes_env_0.1/seq_lib/aes_sanity_vseq.sv,15|64): The randomize method call failed. The unique id of the failed randomize call is 5.\r\nObserved simulation time : 798988 PS + 8\r\nUVM_FATAL @    798988 ps: (aes_sanity_vseq.sv:15) uvm_test_top.env.virtual_sequencer [uvm_test_top.env.virtual_sequencer.aes_sanity_vseq] Check failed (aes_item.randomize() with {key_size == 3'b001;}) Randomization failed! \r\nUVM_INFO @    798988 ps: (uvm_report_catcher.svh:705) [UVM/REPORT/CATCHER] \r\n```\r\n\r\nI am temporarily removing aes_sanity from the sanity regression list so that the CI is happy. Please prioritize on fixing this test. ",
    "error_message": "Unsupported datatype in constraint.\r\n    `DV_CHECK_RANDOMIZE_WITH_FATAL(aes_item, key_size == 3'b001;)\r\n                                                                |\r\nxmsim: *W,SVRNDF (scratch/aes.sim.xcelium/dvsim-err-on-exit/default/src/lowrisc_dv_aes_env_0.1/seq_lib/aes_sanity_vseq.sv,15|64): The randomize method call failed. The unique id of the failed randomize call is 5.\r",
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "FUNCTIONAL",
    "root_cause": "invalid constraint in testbench",
    "labels": [
      "Component:DV",
      "Priority:P1",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-03-05T23:16:04Z",
    "updated_at": "2020-03-11T17:04:53Z",
    "closed_at": "2020-03-11T17:04:53Z",
    "url": "https://github.com/lowRISC/opentitan/issues/1696",
    "comments_count": 16,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/1696/comments"
  },
  {
    "bug_id": "OT-1692",
    "title": "[dvsim] Return non-zero exit code if a regression fails",
    "description": "Currently `util/dvsim.py` always returns a 0 exit code, even if a regression fails. That makes it hard to use this script in CI. Can we change that to return a non-zero exit code if any regression fails?",
    "error_message": null,
    "module": "unknown",
    "severity": "HIGH",
    "priority": "P1",
    "bug_type": "OTHER",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Component:Tooling",
      "Priority:P1",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-03-05T10:09:18Z",
    "updated_at": "2020-03-11T01:22:47Z",
    "closed_at": "2020-03-11T01:22:47Z",
    "url": "https://github.com/lowRISC/opentitan/issues/1692",
    "comments_count": 4,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/1692/comments"
  },
  {
    "bug_id": "OT-1587",
    "title": "[hw, dpi] Shutdown crash in dmidpi",
    "description": "Steps to reproduce:\r\nBuild verilator:\r\n`fusesoc --cores-root . run --target=sim --setup --build lowrisc:systems:top_earlgrey_verilator`\r\n\r\nRun verilator:\r\n`$REPO_TOP/build/lowrisc_systems_top_earlgrey_verilator_0.1/sim-verilator/Vtop_earlgrey_verilator`\r\n\r\nEnd simulation by pressing `CTRL + C`, should result in:\r\n```\r\nfree(): corrupted unsorted chunks\r\nAborted (core dumped)\r\n```\r\n\r\nThe problem seems to be an attempt to free already freed memory (double free), running `valgrind --tool=memcheck`, produces the following trace:\r\n\r\n`valgrind --tool=memcheck -s build/lowrisc_systems_top_earlgrey_verilator_0.1/sim-verilator/Vtop_earlgrey_verilator`\r\n\r\n```\r\n...\r\n==29807== 1 errors in context 6 of 9:                                                                                                                                                               \r\n==29807== Invalid free() / delete / delete[] / realloc()                                                                                                                                            \r\n==29807==    at 0x48399AB: free (vg_replace_malloc.c:540)                                                                                                                                           \r\n==29807==    by 0x110CEC: ctx_free(tcp_server_ctx*) (tcp_server.c:89)                                                                                                                               \r\n==29807==    by 0x10F300: dmidpi_close (dmidpi.c:404)                                                                                                                                               \r\n==29807==    by 0x1371DA: __Vdpiimwrap_top_earlgrey_verilator__DOT__top_earlgrey__DOT__u_dm_top__DOT__u_dmidpi__DOT__dmidpi_close_TOP (Vtop_earlgrey_verilator.cpp:291)                             \r\n==29807==    by 0x1371DA: Vtop_earlgrey_verilator::_final_TOP(Vtop_earlgrey_verilator__Syms*) (Vtop_earlgrey_verilator.cpp:602)                                                                     \r\n==29807==    by 0x1E9190: Vtop_earlgrey_verilator::final() (Vtop_earlgrey_verilator.cpp:241061)                                                                                                     \r\n==29807==    by 0x1178E4: final (verilated_toplevel.h:144)                                                                                                                                          \r\n==29807==    by 0x1178E4: VerilatorSimCtrl::Run() (verilator_sim_ctrl.cc:325)                                                                                                                       \r\n==29807==    by 0x117AB6: VerilatorSimCtrl::RunSimulation() (verilator_sim_ctrl.cc:71)                                                                                                              \r\n==29807==    by 0x117E87: VerilatorSimCtrl::Exec(int, char**) (verilator_sim_ctrl.cc:51)                                                                                                            \r\n==29807==    by 0x10ED52: main (top_earlgrey_verilator.cc:38)                                                                                                                                       \r\n==29807==  Address 0x4e1bda0 is 0 bytes inside a block of size 264 free'd                                                                                                                           \r\n==29807==    at 0x48399AB: free (vg_replace_malloc.c:540)                                                                                                                                           \r\n==29807==    by 0x110CEC: ctx_free(tcp_server_ctx*) (tcp_server.c:89)                                                                                                                               \r\n==29807==    by 0x111403: server_create(void*) (tcp_server.c:377)                                                                                                                                   \r\n==29807==    by 0x4C1D4CE: start_thread (in /usr/lib/libpthread-2.30.so)                                                                                                                            \r\n==29807==    by 0x4D352D2: clone (in /usr/lib/libc-2.30.so)                                                                                                                                         \r\n==29807==  Block was alloc'd at                                                                                                                                                                     \r\n==29807==    at 0x483877F: malloc (vg_replace_malloc.c:309)                                                                                                                                         \r\n==29807==    by 0x110D93: tcp_buffer_new (tcp_server.c:82)                                                                                                                                          \r\n==29807==    by 0x110D93: tcp_server_create (tcp_server.c:389)                                                                                                                                      \r\n==29807==    by 0x10F2AC: dmidpi_create (dmidpi.c:383)                                                                                                                                              \r\n==29807==    by 0x13E111: __Vdpiimwrap_top_earlgrey_verilator__DOT__top_earlgrey__DOT__u_dm_top__DOT__u_dmidpi__DOT__dmidpi_create_TOP (Vtop_earlgrey_verilator.cpp:254)                            \r\n==29807==    by 0x13E111: Vtop_earlgrey_verilator::_initial__TOP__1(Vtop_earlgrey_verilator__Syms*) (Vtop_earlgrey_verilator.cpp:12000)                                                             \r\n==29807==    by 0x21CBA1: Vtop_earlgrey_verilator::_eval_initial(Vtop_earlgrey_verilator__Syms*) (Vtop_earlgrey_verilator.cpp:241018)                                                               \r\n==29807==    by 0x28DF4E: Vtop_earlgrey_verilator::_eval_initial_loop(Vtop_earlgrey_verilator__Syms*) (Vtop_earlgrey_verilator.cpp:222)                                                             \r\n==29807==    by 0x28E067: Vtop_earlgrey_verilator::eval() (Vtop_earlgrey_verilator.cpp:198)                                                                                                         \r\n==29807==    by 0x1175A0: eval (verilated_toplevel.h:143)                                                                                                                                           \r\n==29807==    by 0x1175A0: VerilatorSimCtrl::Run() (verilator_sim_ctrl.cc:277)                                                                                                                       \r\n==29807==    by 0x117AB6: VerilatorSimCtrl::RunSimulation() (verilator_sim_ctrl.cc:71)                                                                                                              \r\n==29807==    by 0x117E87: VerilatorSimCtrl::Exec(int, char**) (verilator_sim_ctrl.cc:51)                                                                                                            \r\n==29807==    by 0x10ED52: main (top_earlgrey_verilator.cc:38)\r\n...\r\n```\r\n\r\nGDB seems to confirm it first call to `ctx_free` is fine, and the second one faults.",
    "error_message": "free(): corrupted unsorted chunks\r\nAborted (core dumped)",
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "TIMING",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2020-02-21T16:44:49Z",
    "updated_at": "2020-02-24T15:54:02Z",
    "closed_at": "2020-02-24T15:54:02Z",
    "url": "https://github.com/lowRISC/opentitan/issues/1587",
    "comments_count": 1,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/1587/comments"
  },
  {
    "bug_id": "OT-453",
    "title": "[tl_agent,dv] Randomization failed in tl_reg_adapter.sv",
    "description": "Commit #433 \r\n\r\n![image](https://user-images.githubusercontent.com/53881329/66730195-e45b9d80-ee04-11e9-9dc0-75bdd9813ca5.png)\r\n\r\nThis error causes several tests failed (i.e. uart sanity and i2c_csr_* etc.)",
    "error_message": null,
    "module": "unknown",
    "severity": "CRITICAL",
    "priority": "P0",
    "bug_type": "FUNCTIONAL",
    "root_cause": "csr read/write mismatch",
    "labels": [
      "Component:DV",
      "Priority:P0",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2019-10-12T16:57:03Z",
    "updated_at": "2019-10-31T08:37:09Z",
    "closed_at": "2019-10-15T00:49:00Z",
    "url": "https://github.com/lowRISC/opentitan/issues/453",
    "comments_count": 8,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/453/comments"
  },
  {
    "bug_id": "OT-361",
    "title": "[topsim] compile error",
    "description": "After updated to the latest change, it shows compile error while running top sim (chip_sanity)\r\n\r\n```\r\nError-[UPIMI-E] Undefined port in module instantiation\r\n/hw/ip/rv_core_ibex/rtl/rv_core_ibex.sv, 288\r\n  Port \"valid_i\" is not defined in module 'ibex_tracer' defined in\r\n  \"/hw/vendor/lowrisc_ibex/rtl/ibex_tracer.sv\",\r\n  33\r\n  Module instance: ibex_tracer ibex_tracer_i( .clk_i (clk_i),  .rst_ni\r\n  (rst_ni),  .fetch_enable_i (fetch_enable_i),  .hart_id_i (hart_id_i),\r\n  .valid_i (rvfi_valid),  .pc_i (rvfi ...\r\n\r\n\r\nError-[UPIMI-E] Undefined port in module instantiation\r\n/hw/ip/rv_core_ibex/rtl/rv_core_ibex.sv, 288\r\n  Port \"pc_i\" is not defined in module 'ibex_tracer' defined in\r\n  \"/hw/vendor/lowrisc_ibex/rtl/ibex_tracer.sv\",\r\n  33\r\n  Module instance: ibex_tracer ibex_tracer_i( .clk_i (clk_i),  .rst_ni\r\n  (rst_ni),  .fetch_enable_i (fetch_enable_i),  .hart_id_i (hart_id_i),\r\n  .valid_i (rvfi_valid),  .pc_i (rvfi ...\r\n\r\n```",
    "error_message": "Error-[UPIMI-E] Undefined port in module instantiation\r\n/hw/ip/rv_core_ibex/rtl/rv_core_ibex.sv, 288\r\n  Port \"valid_i\" is not defined in module 'ibex_tracer' defined in\r\n  \"/hw/vendor/lowrisc_ibex/rtl/ibex_tracer.sv\",\r\n  33\r\n  Module instance: ibex_tracer ibex_tracer_i( .clk_i (clk_i),  .rst_ni\r\n  (rst_ni),  .fetch_enable_i (fetch_enable_i),  .hart_id_i (hart_id_i),\r\n  .valid_i (rvfi_valid),  .pc_i (rvfi ...\r\n\r\n\r\nError-[UPIMI-E] Undefined port in module instantiation\r\n/hw/ip/rv_core_ibex/rtl/rv_core_ibex.sv, 288\r\n  Port \"pc_i\" is not defined in module 'ibex_tracer' defined in\r\n  \"/hw/vendor/lowrisc_ibex/rtl/ibex_tracer.sv\",\r\n  33\r\n  Module instance: ibex_tracer ibex_tracer_i( .clk_i (clk_i),  .rst_ni\r\n  (rst_ni),  .fetch_enable_i (fetch_enable_i),  .hart_id_i (hart_id_i),\r\n  .valid_i (rvfi_valid),  .pc_i (rvfi ...",
    "module": "unknown",
    "severity": "CRITICAL",
    "priority": "P0",
    "bug_type": "FUNCTIONAL",
    "root_cause": "fsm stuck due to timing",
    "labels": [
      "Component:DV",
      "Priority:P0",
      "Type:Bug",
      "Component:RTL"
    ],
    "state": "closed",
    "created_at": "2019-10-07T16:43:54Z",
    "updated_at": "2019-10-07T17:38:30Z",
    "closed_at": "2019-10-07T17:38:30Z",
    "url": "https://github.com/lowRISC/opentitan/issues/361",
    "comments_count": 5,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/361/comments"
  },
  {
    "bug_id": "OT-273",
    "title": "[TL-UL] respond error if memory write isn't word-aligned ",
    "description": "@eunchan \r\nAs discussed, if memory write isn't word-aligned, respond error to make it consistent as register write.",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "P2",
    "bug_type": "MEMORY",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P2",
      "Type:Bug",
      "Component:RTL"
    ],
    "state": "closed",
    "created_at": "2019-09-26T00:13:59Z",
    "updated_at": "2019-10-25T16:58:20Z",
    "closed_at": "2019-10-25T16:58:20Z",
    "url": "https://github.com/lowRISC/opentitan/issues/273",
    "comments_count": 7,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/273/comments"
  },
  {
    "bug_id": "OT-241",
    "title": "[hmac/dv/xcelium] test fails for hmac=1  ",
    "description": "when running the hmac test it fails for any seed that sets the hmac=1 parameter\r\nif I manipulate the test to never set hmac=1 the test passes.\r\nthe error is a unix interrupt signal being raised\r\n\r\ncommand used:\r\n`make TEST_NAME=hmac_sanity SEED=1 SIMULATOR=xcelium`\r\n\r\n\r\nxmsim: *F,SIGUSR: Unix Signal SIGSEGV raised from user application code.\r\n\r\n![image](https://user-images.githubusercontent.com/53917183/65420542-b2f14280-de01-11e9-8b73-9af917005b28.png)\r\n",
    "error_message": null,
    "module": "unknown",
    "severity": "MEDIUM",
    "priority": "unknown",
    "bug_type": "FUNCTIONAL",
    "root_cause": "randomization sensitivity issue",
    "labels": [
      "Component:DV",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2019-09-23T11:01:49Z",
    "updated_at": "2019-11-12T13:21:04Z",
    "closed_at": "2019-11-12T13:21:04Z",
    "url": "https://github.com/lowRISC/opentitan/issues/241",
    "comments_count": 15,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/241/comments"
  },
  {
    "bug_id": "OT-39",
    "title": "Verilator compilation error (jtagdpi) on macOS",
    "description": "I am seeing below error(jtagdpi.c) on macOS with verilator.\r\n\r\n```\r\n      ssize_t num_written = send(ctx->cfd, &tdo_ascii, sizeof(tdo_ascii),\r\n                                 MSG_NOSIGNAL);\r\n ```\r\n\r\nIt complains `MSG_NOSIGNAL` isn't defined. Does anyone see this?",
    "error_message": "ssize_t num_written = send(ctx->cfd, &tdo_ascii, sizeof(tdo_ascii),\r\n                                 MSG_NOSIGNAL);",
    "module": "unknown",
    "severity": "LOW",
    "priority": "P3",
    "bug_type": "FUNCTIONAL",
    "root_cause": "dv environment or config mismatch",
    "labels": [
      "Component:DV",
      "Priority:P3",
      "Type:Bug"
    ],
    "state": "closed",
    "created_at": "2019-06-23T17:52:10Z",
    "updated_at": "2019-12-05T17:35:27Z",
    "closed_at": "2019-12-05T17:35:27Z",
    "url": "https://github.com/lowRISC/opentitan/issues/39",
    "comments_count": 3,
    "comments_url": "https://api.github.com/repos/lowRISC/opentitan/issues/39/comments"
  }
]